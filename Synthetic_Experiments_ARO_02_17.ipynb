{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "675324d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Academic license - for non-commercial use only - expires 2022-09-11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: redefinition of constant GRB_ENV. This may fail, cause incorrect answers, or produce other errors.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Gurobi.Env(Ptr{Nothing} @0x00007f9f0c827c00, false, 0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using CSV, DataFrames, Statistics, StatsBase, Distributions, JuMP, Gurobi, LinearAlgebra, Plots, Pkg\n",
    "const GRB_ENV = Gurobi.Env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d334392e",
   "metadata": {},
   "outputs": [
    {
     "ename": "BoundsError",
     "evalue": "BoundsError: attempt to access 9-element BitVector at index [0:5]",
     "output_type": "error",
     "traceback": [
      "KERNEL EXCEPTION",
      "BoundsError: attempt to access 9-element BitVector at index [0:5]",
      "",
      "Stacktrace:",
      "  [1] throw_boundserror(A::BitVector, I::Tuple{UnitRange{Int64}})",
      "    @ Base /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [2] _simplify_include_frames(trace::Vector{Any})",
      "    @ Base /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [3] process_backtrace(t::Vector{Union{Ptr{Nothing}, Base.InterpreterIP}}, limit::Int64; skipC::Bool)",
      "    @ Base /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [4] process_backtrace (repeats 2 times)",
      "    @ ./errorshow.jl:825 [inlined]",
      "  [5] show_backtrace(io::IOBuffer, t::Vector{Union{Ptr{Nothing}, Base.InterpreterIP}})",
      "    @ Base ./errorshow.jl:759",
      "  [6] show_bt(io::IOBuffer, top_func::Symbol, t::Vector{Union{Ptr{Nothing}, Base.InterpreterIP}}, set::UnitRange{Int64})",
      "    @ IJulia ~/.julia/packages/IJulia/e8kqU/src/display.jl:142",
      "  [7] sprint(::Function, ::Symbol, ::Vararg{Any, N} where N; context::Nothing, sizehint::Int64)",
      "    @ Base ./strings/io.jl:105",
      "  [8] sprint",
      "    @ ./strings/io.jl:101 [inlined]",
      "  [9] error_content(e::LoadError, bt::Vector{Union{Ptr{Nothing}, Base.InterpreterIP}}; backtrace_top::Symbol, msg::String)",
      "    @ IJulia ~/.julia/packages/IJulia/e8kqU/src/display.jl:153",
      " [10] error_content(e::LoadError, bt::Vector{Union{Ptr{Nothing}, Base.InterpreterIP}})",
      "    @ IJulia ~/.julia/packages/IJulia/e8kqU/src/display.jl:153",
      " [11] execute_request(socket::ZMQ.Socket, msg::IJulia.Msg)",
      "    @ IJulia ~/.julia/packages/IJulia/e8kqU/src/execute_request.jl:138",
      " [12] #invokelatest#2",
      "    @ ./essentials.jl:708 [inlined]",
      " [13] invokelatest",
      "    @ ./essentials.jl:706 [inlined]",
      " [14] eventloop(socket::ZMQ.Socket)",
      "    @ IJulia ~/.julia/packages/IJulia/e8kqU/src/eventloop.jl:8",
      " [15] (::IJulia.var\"#15#18\")()",
      "    @ IJulia ./task.jl:411"
     ]
    }
   ],
   "source": [
    "include(\"adaptive_ensemble/src/main.jl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbc03a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c7b9dfad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"150\" height=\"100\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip430\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip430)\" d=\"\n",
       "M0 400 L600 400 L600 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip431\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip430)\" d=\"\n",
       "M44.9134 371.612 L588.189 371.612 L588.189 11.811 L44.9134 11.811  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip432\">\n",
       "    <rect x=\"44\" y=\"11\" width=\"544\" height=\"361\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  59.5861,371.612 59.5861,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  200.196,371.612 200.196,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  340.806,371.612 340.806,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  481.417,371.612 481.417,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,371.612 588.189,371.612 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  59.5861,371.612 59.5861,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  200.196,371.612 200.196,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  340.806,371.612 340.806,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  481.417,371.612 481.417,367.294 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip430)\" d=\"M 0 0 M59.5861 378.91 Q58.6833 378.91 58.2261 379.801 Q57.7748 380.686 57.7748 382.469 Q57.7748 384.245 58.2261 385.136 Q58.6833 386.022 59.5861 386.022 Q60.4946 386.022 60.946 385.136 Q61.4032 384.245 61.4032 382.469 Q61.4032 380.686 60.946 379.801 Q60.4946 378.91 59.5861 378.91 M59.5861 377.984 Q61.0386 377.984 61.8025 379.135 Q62.5722 380.281 62.5722 382.469 Q62.5722 384.65 61.8025 385.802 Q61.0386 386.948 59.5861 386.948 Q58.1336 386.948 57.3639 385.802 Q56.6 384.65 56.6 382.469 Q56.6 380.281 57.3639 379.135 Q58.1336 377.984 59.5861 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M192.106 385.796 L196.186 385.796 L196.186 386.78 L190.7 386.78 L190.7 385.796 Q191.365 385.108 192.511 383.95 Q193.663 382.787 193.958 382.451 Q194.519 381.821 194.739 381.386 Q194.965 380.947 194.965 380.524 Q194.965 379.836 194.479 379.402 Q193.998 378.968 193.223 378.968 Q192.673 378.968 192.06 379.158 Q191.452 379.349 190.758 379.737 L190.758 378.557 Q191.464 378.273 192.077 378.128 Q192.691 377.984 193.2 377.984 Q194.542 377.984 195.341 378.655 Q196.14 379.326 196.14 380.449 Q196.14 380.981 195.937 381.462 Q195.74 381.936 195.214 382.584 Q195.069 382.752 194.294 383.557 Q193.518 384.355 192.106 385.796 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M199.953 378.91 Q199.05 378.91 198.593 379.801 Q198.142 380.686 198.142 382.469 Q198.142 384.245 198.593 385.136 Q199.05 386.022 199.953 386.022 Q200.862 386.022 201.313 385.136 Q201.77 384.245 201.77 382.469 Q201.77 380.686 201.313 379.801 Q200.862 378.91 199.953 378.91 M199.953 377.984 Q201.406 377.984 202.17 379.135 Q202.939 380.281 202.939 382.469 Q202.939 384.65 202.17 385.802 Q201.406 386.948 199.953 386.948 Q198.501 386.948 197.731 385.802 Q196.967 384.65 196.967 382.469 Q196.967 380.281 197.731 379.135 Q198.501 377.984 199.953 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M206.707 378.91 Q205.804 378.91 205.347 379.801 Q204.895 380.686 204.895 382.469 Q204.895 384.245 205.347 385.136 Q205.804 386.022 206.707 386.022 Q207.615 386.022 208.067 385.136 Q208.524 384.245 208.524 382.469 Q208.524 380.686 208.067 379.801 Q207.615 378.91 206.707 378.91 M206.707 377.984 Q208.159 377.984 208.923 379.135 Q209.693 380.281 209.693 382.469 Q209.693 384.65 208.923 385.802 Q208.159 386.948 206.707 386.948 Q205.254 386.948 204.484 385.802 Q203.721 384.65 203.721 382.469 Q203.721 380.281 204.484 379.135 Q205.254 377.984 206.707 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M334.805 379.158 L331.854 383.771 L334.805 383.771 L334.805 379.158 M334.499 378.14 L335.969 378.14 L335.969 383.771 L337.201 383.771 L337.201 384.743 L335.969 384.743 L335.969 386.78 L334.805 386.78 L334.805 384.743 L330.905 384.743 L330.905 383.614 L334.499 378.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M340.968 378.91 Q340.066 378.91 339.609 379.801 Q339.157 380.686 339.157 382.469 Q339.157 384.245 339.609 385.136 Q340.066 386.022 340.968 386.022 Q341.877 386.022 342.328 385.136 Q342.786 384.245 342.786 382.469 Q342.786 380.686 342.328 379.801 Q341.877 378.91 340.968 378.91 M340.968 377.984 Q342.421 377.984 343.185 379.135 Q343.955 380.281 343.955 382.469 Q343.955 384.65 343.185 385.802 Q342.421 386.948 340.968 386.948 Q339.516 386.948 338.746 385.802 Q337.982 384.65 337.982 382.469 Q337.982 380.281 338.746 379.135 Q339.516 377.984 340.968 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M347.722 378.91 Q346.819 378.91 346.362 379.801 Q345.911 380.686 345.911 382.469 Q345.911 384.245 346.362 385.136 Q346.819 386.022 347.722 386.022 Q348.63 386.022 349.082 385.136 Q349.539 384.245 349.539 382.469 Q349.539 380.686 349.082 379.801 Q348.63 378.91 347.722 378.91 M347.722 377.984 Q349.174 377.984 349.938 379.135 Q350.708 380.281 350.708 382.469 Q350.708 384.65 349.938 385.802 Q349.174 386.948 347.722 386.948 Q346.269 386.948 345.5 385.802 Q344.736 384.65 344.736 382.469 Q344.736 380.281 345.5 379.135 Q346.269 377.984 347.722 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M474.764 381.994 Q473.977 381.994 473.514 382.532 Q473.057 383.07 473.057 384.008 Q473.057 384.94 473.514 385.484 Q473.977 386.022 474.764 386.022 Q475.552 386.022 476.009 385.484 Q476.472 384.94 476.472 384.008 Q476.472 383.07 476.009 382.532 Q475.552 381.994 474.764 381.994 M477.085 378.331 L477.085 379.396 Q476.645 379.187 476.194 379.077 Q475.748 378.968 475.308 378.968 Q474.151 378.968 473.538 379.749 Q472.93 380.53 472.843 382.11 Q473.185 381.606 473.7 381.34 Q474.215 381.068 474.834 381.068 Q476.136 381.068 476.888 381.861 Q477.646 382.648 477.646 384.008 Q477.646 385.339 476.859 386.143 Q476.072 386.948 474.764 386.948 Q473.266 386.948 472.473 385.802 Q471.68 384.65 471.68 382.469 Q471.68 380.42 472.652 379.205 Q473.624 377.984 475.262 377.984 Q475.702 377.984 476.148 378.071 Q476.599 378.157 477.085 378.331 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M481.414 378.91 Q480.511 378.91 480.054 379.801 Q479.602 380.686 479.602 382.469 Q479.602 384.245 480.054 385.136 Q480.511 386.022 481.414 386.022 Q482.322 386.022 482.774 385.136 Q483.231 384.245 483.231 382.469 Q483.231 380.686 482.774 379.801 Q482.322 378.91 481.414 378.91 M481.414 377.984 Q482.866 377.984 483.63 379.135 Q484.4 380.281 484.4 382.469 Q484.4 384.65 483.63 385.802 Q482.866 386.948 481.414 386.948 Q479.961 386.948 479.192 385.802 Q478.428 384.65 478.428 382.469 Q478.428 380.281 479.192 379.135 Q479.961 377.984 481.414 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M488.167 378.91 Q487.264 378.91 486.807 379.801 Q486.356 380.686 486.356 382.469 Q486.356 384.245 486.807 385.136 Q487.264 386.022 488.167 386.022 Q489.076 386.022 489.527 385.136 Q489.984 384.245 489.984 382.469 Q489.984 380.686 489.527 379.801 Q489.076 378.91 488.167 378.91 M488.167 377.984 Q489.62 377.984 490.384 379.135 Q491.153 380.281 491.153 382.469 Q491.153 384.65 490.384 385.802 Q489.62 386.948 488.167 386.948 Q486.715 386.948 485.945 385.802 Q485.181 384.65 485.181 382.469 Q485.181 380.281 485.945 379.135 Q486.715 377.984 488.167 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,361.43 588.189,361.43 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,276.571 588.189,276.571 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,191.711 588.189,191.711 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,106.852 588.189,106.852 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip432)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,21.9925 588.189,21.9925 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,371.612 44.9134,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,361.43 51.4327,361.43 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,276.571 51.4327,276.571 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,191.711 51.4327,191.711 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,106.852 51.4327,106.852 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,21.9925 51.4327,21.9925 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip430)\" d=\"M 0 0 M12.8059 361.543 L20.2248 361.543 L20.2248 362.527 L12.8059 362.527 L12.8059 361.543 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M21.6947 364.767 L23.6045 364.767 L23.6045 358.175 L21.5269 358.592 L21.5269 357.527 L23.5929 357.11 L24.7619 357.11 L24.7619 364.767 L26.6716 364.767 L26.6716 365.75 L21.6947 365.75 L21.6947 364.767 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M27.9389 364.281 L29.16 364.281 L29.16 365.75 L27.9389 365.75 L27.9389 364.281 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M32.9273 357.88 Q32.0245 357.88 31.5674 358.771 Q31.116 359.657 31.116 361.439 Q31.116 363.216 31.5674 364.107 Q32.0245 364.992 32.9273 364.992 Q33.8359 364.992 34.2873 364.107 Q34.7444 363.216 34.7444 361.439 Q34.7444 359.657 34.2873 358.771 Q33.8359 357.88 32.9273 357.88 M32.9273 356.954 Q34.3799 356.954 35.1437 358.106 Q35.9134 359.252 35.9134 361.439 Q35.9134 363.621 35.1437 364.772 Q34.3799 365.918 32.9273 365.918 Q31.4748 365.918 30.7051 364.772 Q29.9412 363.621 29.9412 361.439 Q29.9412 359.252 30.7051 358.106 Q31.4748 356.954 32.9273 356.954 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M12.748 276.684 L20.167 276.684 L20.167 277.668 L12.748 277.668 L12.748 276.684 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M23.9343 273.021 Q23.0315 273.021 22.5744 273.912 Q22.123 274.797 22.123 276.58 Q22.123 278.356 22.5744 279.247 Q23.0315 280.133 23.9343 280.133 Q24.8429 280.133 25.2943 279.247 Q25.7514 278.356 25.7514 276.58 Q25.7514 274.797 25.2943 273.912 Q24.8429 273.021 23.9343 273.021 M23.9343 272.095 Q25.3869 272.095 26.1507 273.246 Q26.9204 274.392 26.9204 276.58 Q26.9204 278.761 26.1507 279.913 Q25.3869 281.059 23.9343 281.059 Q22.4818 281.059 21.7121 279.913 Q20.9482 278.761 20.9482 276.58 Q20.9482 274.392 21.7121 273.246 Q22.4818 272.095 23.9343 272.095 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M28.1878 279.421 L29.4088 279.421 L29.4088 280.891 L28.1878 280.891 L28.1878 279.421 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M30.6878 272.251 L35.2768 272.251 L35.2768 273.235 L31.7583 273.235 L31.7583 275.353 Q32.013 275.266 32.2676 275.226 Q32.5222 275.179 32.7769 275.179 Q34.2236 275.179 35.0685 275.972 Q35.9134 276.765 35.9134 278.119 Q35.9134 279.514 35.0454 280.289 Q34.1773 281.059 32.5975 281.059 Q32.0535 281.059 31.4864 280.966 Q30.925 280.874 30.3232 280.688 L30.3232 279.514 Q30.844 279.797 31.3996 279.936 Q31.9551 280.075 32.5743 280.075 Q33.5755 280.075 34.16 279.548 Q34.7444 279.022 34.7444 278.119 Q34.7444 277.216 34.16 276.69 Q33.5755 276.163 32.5743 276.163 Q32.1056 276.163 31.6368 276.267 Q31.1739 276.371 30.6878 276.591 L30.6878 272.251 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M23.6855 188.161 Q22.7827 188.161 22.3255 189.052 Q21.8741 189.938 21.8741 191.72 Q21.8741 193.497 22.3255 194.388 Q22.7827 195.273 23.6855 195.273 Q24.594 195.273 25.0454 194.388 Q25.5026 193.497 25.5026 191.72 Q25.5026 189.938 25.0454 189.052 Q24.594 188.161 23.6855 188.161 M23.6855 187.235 Q25.138 187.235 25.9019 188.387 Q26.6716 189.533 26.6716 191.72 Q26.6716 193.902 25.9019 195.053 Q25.138 196.199 23.6855 196.199 Q22.2329 196.199 21.4633 195.053 Q20.6994 193.902 20.6994 191.72 Q20.6994 189.533 21.4633 188.387 Q22.2329 187.235 23.6855 187.235 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M27.9389 194.562 L29.16 194.562 L29.16 196.031 L27.9389 196.031 L27.9389 194.562 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M32.9273 188.161 Q32.0245 188.161 31.5674 189.052 Q31.116 189.938 31.116 191.72 Q31.116 193.497 31.5674 194.388 Q32.0245 195.273 32.9273 195.273 Q33.8359 195.273 34.2873 194.388 Q34.7444 193.497 34.7444 191.72 Q34.7444 189.938 34.2873 189.052 Q33.8359 188.161 32.9273 188.161 M32.9273 187.235 Q34.3799 187.235 35.1437 188.387 Q35.9134 189.533 35.9134 191.72 Q35.9134 193.902 35.1437 195.053 Q34.3799 196.199 32.9273 196.199 Q31.4748 196.199 30.7051 195.053 Q29.9412 193.902 29.9412 191.72 Q29.9412 189.533 30.7051 188.387 Q31.4748 187.235 32.9273 187.235 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M23.9343 103.302 Q23.0315 103.302 22.5744 104.193 Q22.123 105.078 22.123 106.861 Q22.123 108.637 22.5744 109.528 Q23.0315 110.414 23.9343 110.414 Q24.8429 110.414 25.2943 109.528 Q25.7514 108.637 25.7514 106.861 Q25.7514 105.078 25.2943 104.193 Q24.8429 103.302 23.9343 103.302 M23.9343 102.376 Q25.3869 102.376 26.1507 103.527 Q26.9204 104.673 26.9204 106.861 Q26.9204 109.042 26.1507 110.194 Q25.3869 111.34 23.9343 111.34 Q22.4818 111.34 21.7121 110.194 Q20.9482 109.042 20.9482 106.861 Q20.9482 104.673 21.7121 103.527 Q22.4818 102.376 23.9343 102.376 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M28.1878 109.702 L29.4088 109.702 L29.4088 111.172 L28.1878 111.172 L28.1878 109.702 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M30.6878 102.532 L35.2768 102.532 L35.2768 103.516 L31.7583 103.516 L31.7583 105.634 Q32.013 105.547 32.2676 105.507 Q32.5222 105.46 32.7769 105.46 Q34.2236 105.46 35.0685 106.253 Q35.9134 107.046 35.9134 108.4 Q35.9134 109.795 35.0454 110.57 Q34.1773 111.34 32.5975 111.34 Q32.0535 111.34 31.4864 111.247 Q30.925 111.155 30.3232 110.969 L30.3232 109.795 Q30.844 110.078 31.3996 110.217 Q31.9551 110.356 32.5743 110.356 Q33.5755 110.356 34.16 109.829 Q34.7444 109.303 34.7444 108.4 Q34.7444 107.497 34.16 106.971 Q33.5755 106.444 32.5743 106.444 Q32.1056 106.444 31.6368 106.548 Q31.1739 106.652 30.6878 106.872 L30.6878 102.532 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M21.6947 25.3287 L23.6045 25.3287 L23.6045 18.7373 L21.5269 19.154 L21.5269 18.0892 L23.5929 17.6725 L24.7619 17.6725 L24.7619 25.3287 L26.6716 25.3287 L26.6716 26.3125 L21.6947 26.3125 L21.6947 25.3287 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M27.9389 24.8426 L29.16 24.8426 L29.16 26.3125 L27.9389 26.3125 L27.9389 24.8426 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M32.9273 18.4422 Q32.0245 18.4422 31.5674 19.3334 Q31.116 20.2188 31.116 22.0012 Q31.116 23.7778 31.5674 24.669 Q32.0245 25.5544 32.9273 25.5544 Q33.8359 25.5544 34.2873 24.669 Q34.7444 23.7778 34.7444 22.0012 Q34.7444 20.2188 34.2873 19.3334 Q33.8359 18.4422 32.9273 18.4422 M32.9273 17.5162 Q34.3799 17.5162 35.1437 18.6679 Q35.9134 19.8137 35.9134 22.0012 Q35.9134 24.1829 35.1437 25.3345 Q34.3799 26.4803 32.9273 26.4803 Q31.4748 26.4803 30.7051 25.3345 Q29.9412 24.1829 29.9412 22.0012 Q29.9412 19.8137 30.7051 18.6679 Q31.4748 17.5162 32.9273 17.5162 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip432)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  60.2891,185.869 60.9922,180.034 61.6952,174.213 62.3983,168.413 63.1013,162.64 63.8044,156.901 64.5074,151.204 65.2105,145.555 65.9135,139.961 66.6166,134.427 \n",
       "  67.3196,128.962 68.0227,123.571 68.7258,118.261 69.4288,113.038 70.1319,107.908 70.8349,102.878 71.538,97.9527 72.241,93.1387 72.9441,88.4414 73.6471,83.8666 \n",
       "  74.3502,79.4195 75.0532,75.1056 75.7563,70.9298 76.4593,66.8973 77.1624,63.0126 77.8654,59.2805 78.5685,55.7053 79.2715,52.2913 79.9746,49.0426 80.6776,45.9629 \n",
       "  81.3807,43.056 82.0837,40.3253 82.7868,37.774 83.4898,35.4052 84.1929,33.2216 84.8959,31.2258 85.599,29.4203 86.302,27.8071 87.0051,26.3881 87.7081,25.1651 \n",
       "  88.4112,24.1395 89.1142,23.3125 89.8173,22.6851 90.5203,22.258 91.2234,22.0318 91.9264,22.0066 92.6295,22.1826 93.3325,22.5595 94.0356,23.1369 94.7386,23.9141 \n",
       "  95.4417,24.8902 96.1447,26.064 96.8478,27.4341 97.5508,28.9989 98.2539,30.7565 98.9569,32.7049 99.66,34.8418 100.363,37.1646 101.066,39.6705 101.769,42.3567 \n",
       "  102.472,45.2199 103.175,48.2567 103.878,51.4635 104.581,54.8365 105.284,58.3718 105.987,62.0651 106.691,65.912 107.394,69.9081 108.097,74.0485 108.8,78.3284 \n",
       "  109.503,82.7426 110.206,87.286 110.909,91.9532 111.612,96.7386 112.315,101.637 113.018,106.641 113.721,111.747 114.424,116.947 115.127,122.236 115.83,127.607 \n",
       "  116.533,133.055 117.236,138.571 117.939,144.151 118.642,149.787 119.345,155.473 120.048,161.202 120.752,166.967 121.455,172.761 122.158,178.578 122.861,184.41 \n",
       "  123.564,190.251 124.267,196.093 124.97,201.931 125.673,207.756 126.376,213.563 127.079,219.343 127.782,225.091 128.485,230.799 129.188,236.461 129.891,242.069 \n",
       "  130.594,247.618 131.297,253.101 132,258.511 132.703,263.842 133.406,269.088 134.109,274.241 134.813,279.297 135.516,284.249 136.219,289.092 136.922,293.819 \n",
       "  137.625,298.424 138.328,302.904 139.031,307.252 139.734,311.462 140.437,315.531 141.14,319.453 141.843,323.224 142.546,326.839 143.249,330.294 143.952,333.584 \n",
       "  144.655,336.706 145.358,339.657 146.061,342.432 146.764,345.028 147.467,347.443 148.171,349.673 148.874,351.716 149.577,353.569 150.28,355.231 150.983,356.698 \n",
       "  151.686,357.971 152.389,359.046 153.092,359.922 153.795,360.6 154.498,361.077 155.201,361.353 155.904,361.429 156.607,361.303 157.31,360.976 158.013,360.449 \n",
       "  158.716,359.722 159.419,358.795 160.122,357.671 160.825,356.35 161.528,354.833 162.232,353.124 162.935,351.223 163.638,349.133 164.341,346.856 165.044,344.396 \n",
       "  165.747,341.755 166.45,338.935 167.153,335.942 167.856,332.777 168.559,329.445 169.262,325.95 169.965,322.296 170.668,318.487 171.371,314.528 172.074,310.423 \n",
       "  172.777,306.177 173.48,301.796 174.183,297.285 174.886,292.648 175.589,287.892 176.293,283.021 176.996,278.043 177.699,272.962 178.402,267.785 179.105,262.517 \n",
       "  179.808,257.166 180.511,251.737 181.214,246.237 181.917,240.672 182.62,235.05 183.323,229.376 184.026,223.657 184.729,217.901 185.432,212.113 186.135,206.301 \n",
       "  186.838,200.472 187.541,194.633 188.244,188.79 188.947,182.951 189.651,177.122 190.354,171.31 191.057,165.522 191.76,159.766 192.463,154.047 193.166,148.373 \n",
       "  193.869,142.751 194.572,137.186 195.275,131.686 195.978,126.257 196.681,120.906 197.384,115.638 198.087,110.461 198.79,105.38 199.493,100.402 200.196,95.5314 \n",
       "  200.899,90.7751 201.602,86.1383 202.305,81.6267 203.008,77.2456 203.712,73.0001 204.415,68.8954 205.118,64.9361 205.821,61.1272 206.524,57.473 207.227,53.9779 \n",
       "  207.93,50.646 208.633,47.4814 209.336,44.4877 210.039,41.6684 210.742,39.027 211.445,36.5666 212.148,34.2901 212.851,32.2001 213.554,30.2991 214.257,28.5895 \n",
       "  214.96,27.0732 215.663,25.7521 216.366,24.6276 217.069,23.7011 217.773,22.9738 218.476,22.4465 219.179,22.1198 219.882,21.9941 220.585,22.0695 221.288,22.346 \n",
       "  221.991,22.8232 222.694,23.5006 223.397,24.3774 224.1,25.4524 224.803,26.7246 225.506,28.1922 226.209,29.8537 226.912,31.707 227.615,33.75 228.318,35.9801 \n",
       "  229.021,38.3949 229.724,40.9913 230.427,43.7664 231.131,46.7168 231.834,49.8391 232.537,53.1295 233.24,56.5841 233.943,60.199 234.646,63.9696 235.349,67.8917 \n",
       "  236.052,71.9606 236.755,76.1713 237.458,80.519 238.161,84.9985 238.864,89.6045 239.567,94.3314 240.27,99.1738 240.973,104.126 241.676,109.182 242.379,114.335 \n",
       "  243.082,119.581 243.785,124.912 244.488,130.322 245.192,135.805 245.895,141.354 246.598,146.962 247.301,152.624 248.004,158.332 248.707,164.08 249.41,169.86 \n",
       "  250.113,175.667 250.816,181.492 251.519,187.33 252.222,193.172 252.925,199.013 253.628,204.845 254.331,210.662 255.034,216.456 255.737,222.221 256.44,227.95 \n",
       "  257.143,233.636 257.846,239.272 258.549,244.852 259.253,250.368 259.956,255.816 260.659,261.187 261.362,266.476 262.065,271.676 262.768,276.782 263.471,281.786 \n",
       "  264.174,286.684 264.877,291.47 265.58,296.137 266.283,300.68 266.986,305.095 267.689,309.374 268.392,313.515 269.095,317.511 269.798,321.358 270.501,325.051 \n",
       "  271.204,328.586 271.907,331.96 272.611,335.166 273.314,338.203 274.017,341.066 274.72,343.752 275.423,346.258 276.126,348.581 276.829,350.718 277.532,352.666 \n",
       "  278.235,354.424 278.938,355.989 279.641,357.359 280.344,358.533 281.047,359.509 281.75,360.286 282.453,360.863 283.156,361.24 283.859,361.416 284.562,361.391 \n",
       "  285.265,361.165 285.968,360.738 286.672,360.11 287.375,359.283 288.078,358.258 288.781,357.035 289.484,355.616 290.187,354.003 290.89,352.197 291.593,350.201 \n",
       "  292.296,348.018 292.999,345.649 293.702,343.098 294.405,340.367 295.108,337.46 295.811,334.38 296.514,331.132 297.217,327.718 297.92,324.143 298.623,320.41 \n",
       "  299.326,316.526 300.03,312.493 300.733,308.317 301.436,304.003 302.139,299.556 302.842,294.982 303.545,290.284 304.248,285.47 304.951,280.545 305.654,275.515 \n",
       "  306.357,270.385 307.06,265.162 307.763,259.852 308.466,254.461 309.169,248.996 309.872,243.462 310.575,237.868 311.278,232.219 311.981,226.522 312.684,220.783 \n",
       "  313.387,215.01 314.091,209.21 314.794,203.389 315.497,197.553 316.2,191.711 316.903,185.869 317.606,180.034 318.309,174.213 319.012,168.413 319.715,162.64 \n",
       "  320.418,156.901 321.121,151.204 321.824,145.555 322.527,139.961 323.23,134.427 323.933,128.962 324.636,123.571 325.339,118.261 326.042,113.038 326.745,107.908 \n",
       "  327.448,102.878 328.152,97.9527 328.855,93.1387 329.558,88.4414 330.261,83.8666 330.964,79.4195 331.667,75.1056 332.37,70.9298 333.073,66.8973 333.776,63.0126 \n",
       "  334.479,59.2805 335.182,55.7053 335.885,52.2913 336.588,49.0426 337.291,45.9629 337.994,43.056 338.697,40.3253 339.4,37.774 340.103,35.4052 340.806,33.2216 \n",
       "  341.51,31.2258 342.213,29.4203 342.916,27.8071 343.619,26.3881 344.322,25.1651 345.025,24.1395 345.728,23.3125 346.431,22.6851 347.134,22.258 347.837,22.0318 \n",
       "  348.54,22.0066 349.243,22.1826 349.946,22.5595 350.649,23.1369 351.352,23.9141 352.055,24.8902 352.758,26.064 353.461,27.4341 354.164,28.9989 354.867,30.7565 \n",
       "  355.571,32.7049 356.274,34.8418 356.977,37.1646 357.68,39.6705 358.383,42.3567 359.086,45.2199 359.789,48.2567 360.492,51.4635 361.195,54.8365 361.898,58.3718 \n",
       "  362.601,62.0651 363.304,65.912 364.007,69.9081 364.71,74.0485 365.413,78.3284 366.116,82.7426 366.819,87.286 367.522,91.9532 368.225,96.7386 368.928,101.637 \n",
       "  369.632,106.641 370.335,111.747 371.038,116.947 371.741,122.236 372.444,127.607 373.147,133.055 373.85,138.571 374.553,144.151 375.256,149.787 375.959,155.473 \n",
       "  376.662,161.202 377.365,166.967 378.068,172.761 378.771,178.578 379.474,184.41 380.177,190.251 380.88,196.093 381.583,201.931 382.286,207.756 382.99,213.563 \n",
       "  383.693,219.343 384.396,225.091 385.099,230.799 385.802,236.461 386.505,242.069 387.208,247.618 387.911,253.101 388.614,258.511 389.317,263.842 390.02,269.088 \n",
       "  390.723,274.241 391.426,279.297 392.129,284.249 392.832,289.092 393.535,293.819 394.238,298.424 394.941,302.904 395.644,307.252 396.347,311.462 397.051,315.531 \n",
       "  397.754,319.453 398.457,323.224 399.16,326.839 399.863,330.294 400.566,333.584 401.269,336.706 401.972,339.657 402.675,342.432 403.378,345.028 404.081,347.443 \n",
       "  404.784,349.673 405.487,351.716 406.19,353.569 406.893,355.231 407.596,356.698 408.299,357.971 409.002,359.046 409.705,359.922 410.408,360.6 411.112,361.077 \n",
       "  411.815,361.353 412.518,361.429 413.221,361.303 413.924,360.976 414.627,360.449 415.33,359.722 416.033,358.795 416.736,357.671 417.439,356.35 418.142,354.833 \n",
       "  418.845,353.124 419.548,351.223 420.251,349.133 420.954,346.856 421.657,344.396 422.36,341.755 423.063,338.935 423.766,335.942 424.47,332.777 425.173,329.445 \n",
       "  425.876,325.95 426.579,322.296 427.282,318.487 427.985,314.528 428.688,310.423 429.391,306.177 430.094,301.796 430.797,297.285 431.5,292.648 432.203,287.892 \n",
       "  432.906,283.021 433.609,278.043 434.312,272.962 435.015,267.785 435.718,262.517 436.421,257.166 437.124,251.737 437.827,246.237 438.531,240.672 439.234,235.05 \n",
       "  439.937,229.376 440.64,223.657 441.343,217.901 442.046,212.113 442.749,206.301 443.452,200.472 444.155,194.633 444.858,188.79 445.561,182.951 446.264,177.122 \n",
       "  446.967,171.31 447.67,165.522 448.373,159.766 449.076,154.047 449.779,148.373 450.482,142.751 451.185,137.186 451.888,131.686 452.592,126.257 453.295,120.906 \n",
       "  453.998,115.638 454.701,110.461 455.404,105.38 456.107,100.402 456.81,95.5314 457.513,90.7751 458.216,86.1383 458.919,81.6267 459.622,77.2456 460.325,73.0001 \n",
       "  461.028,68.8954 461.731,64.9361 462.434,61.1272 463.137,57.473 463.84,53.9779 464.543,50.646 465.246,47.4814 465.95,44.4877 466.653,41.6684 467.356,39.027 \n",
       "  468.059,36.5666 468.762,34.2901 469.465,32.2001 470.168,30.2991 470.871,28.5895 471.574,27.0732 472.277,25.7521 472.98,24.6276 473.683,23.7011 474.386,22.9738 \n",
       "  475.089,22.4465 475.792,22.1198 476.495,21.9941 477.198,22.0695 477.901,22.346 478.604,22.8232 479.307,23.5006 480.011,24.3774 480.714,25.4524 481.417,26.7246 \n",
       "  482.12,28.1922 482.823,29.8537 483.526,31.707 484.229,33.75 484.932,35.9801 485.635,38.3949 486.338,40.9913 487.041,43.7664 487.744,46.7168 488.447,49.8391 \n",
       "  489.15,53.1295 489.853,56.5841 490.556,60.199 491.259,63.9696 491.962,67.8917 492.665,71.9606 493.369,76.1713 494.072,80.519 494.775,84.9985 495.478,89.6045 \n",
       "  496.181,94.3314 496.884,99.1738 497.587,104.126 498.29,109.182 498.993,114.335 499.696,119.581 500.399,124.912 501.102,130.322 501.805,135.805 502.508,141.354 \n",
       "  503.211,146.962 503.914,152.624 504.617,158.332 505.32,164.08 506.023,169.86 506.726,175.667 507.43,181.492 508.133,187.33 508.836,193.172 509.539,199.013 \n",
       "  510.242,204.845 510.945,210.662 511.648,216.456 512.351,222.221 513.054,227.95 513.757,233.636 514.46,239.272 515.163,244.852 515.866,250.368 516.569,255.816 \n",
       "  517.272,261.187 517.975,266.476 518.678,271.676 519.381,276.782 520.084,281.786 520.787,286.684 521.491,291.47 522.194,296.137 522.897,300.68 523.6,305.095 \n",
       "  524.303,309.374 525.006,313.515 525.709,317.511 526.412,321.358 527.115,325.051 527.818,328.586 528.521,331.96 529.224,335.166 529.927,338.203 530.63,341.066 \n",
       "  531.333,343.752 532.036,346.258 532.739,348.581 533.442,350.718 534.145,352.666 534.849,354.424 535.552,355.989 536.255,357.359 536.958,358.533 537.661,359.509 \n",
       "  538.364,360.286 539.067,360.863 539.77,361.24 540.473,361.416 541.176,361.391 541.879,361.165 542.582,360.738 543.285,360.11 543.988,359.283 544.691,358.258 \n",
       "  545.394,357.035 546.097,355.616 546.8,354.003 547.503,352.197 548.206,350.201 548.91,348.018 549.613,345.649 550.316,343.098 551.019,340.367 551.722,337.46 \n",
       "  552.425,334.38 553.128,331.132 553.831,327.718 554.534,324.143 555.237,320.41 555.94,316.526 556.643,312.493 557.346,308.317 558.049,304.003 558.752,299.556 \n",
       "  559.455,294.982 560.158,290.284 560.861,285.47 561.564,280.545 562.267,275.515 562.971,270.385 563.674,265.162 564.377,259.852 565.08,254.461 565.783,248.996 \n",
       "  566.486,243.462 567.189,237.868 567.892,232.219 568.595,226.522 569.298,220.783 570.001,215.01 570.704,209.21 571.407,203.389 572.11,197.553 572.813,191.711 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip430)\" d=\"\n",
       "M496.961 54.0444 L570.08 54.0444 L570.08 23.8044 L496.961 23.8044  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  496.961,54.0444 570.08,54.0444 570.08,23.8044 496.961,23.8044 496.961,54.0444 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip430)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  502.998,38.9244 539.216,38.9244 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip430)\" d=\"M 0 0 M548.713 43.8462 Q548.262 45.0036 547.833 45.3566 Q547.405 45.7097 546.688 45.7097 L545.837 45.7097 L545.837 44.8185 L546.462 44.8185 Q546.902 44.8185 547.145 44.6101 Q547.388 44.4018 547.683 43.6263 L547.874 43.1402 L545.252 36.7629 L546.381 36.7629 L548.406 41.8324 L550.432 36.7629 L551.56 36.7629 L548.713 43.8462 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip430)\" d=\"M 0 0 M553.03 42.2606 L554.94 42.2606 L554.94 35.6692 L552.862 36.0859 L552.862 35.0211 L554.928 34.6044 L556.097 34.6044 L556.097 42.2606 L558.007 42.2606 L558.007 43.2444 L553.03 43.2444 L553.03 42.2606 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = 365\n",
    "period = 2\n",
    "y = [sin(2*pi*period*t/T) for t=1:2T]\n",
    "plot(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5121e00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "create_ensemble_values (generic function with 2 methods)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function create_y(T, period, bias, σ_pert)\n",
    "    d = Normal(0, σ_pert)\n",
    "    y_base = [sin(2*pi*period*t/T) for t=1:2T]\n",
    "    y = y_base.+rand(d, size(y_base))\n",
    "    return y\n",
    "end\n",
    "\n",
    "function create_ensemble_values(y, N_models, bias_range, std_range, δ_pert, σ_pert, total_drift_additive)\n",
    "    #uniform distribution of models biases\n",
    "    T = size(y)[1]\n",
    "    d = Uniform(-bias_range, bias_range)\n",
    "    \n",
    "    #sample distribution of models biases\n",
    "    biases = rand(d, N_models)\n",
    "    \n",
    "    #uniform distribution of models stds\n",
    "    s = Uniform(0, std_range)\n",
    "    \n",
    "    #sample distribution of models biases\n",
    "    variances = rand(s, N_models)\n",
    "    \n",
    "    #Create the features X by taking y and adding noise.\n",
    "    X = zeros(T, N_models)\n",
    "\n",
    "    for i=1:N_models\n",
    "        d = Normal(biases[i], variances[i])\n",
    "        X[:,i] = y.+ rand(d, T)\n",
    "    end\n",
    "    \n",
    "    if total_drift_additive\n",
    "        #### Perturbations on base learners because of data drift\n",
    "        d = Normal(0, δ_pert)\n",
    "        biases_perturb = rand(d, N_models)\n",
    "        d = Uniform(0, σ_pert)\n",
    "        variances_perturb = rand(d, N_models)\n",
    "        for i=1:N_models\n",
    "            d = Normal(biases_perturb[i], variances_perturb[i])\n",
    "            X[:,i] = X[:,i] .+ [t/T for t=1:T].*rand(d, T)\n",
    "        end\n",
    "    end\n",
    "    return X\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5e15614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "730×10 Matrix{Float64}:\n",
       "  0.0150678   0.277899     0.0853916   …   0.0985742   -0.331979\n",
       "  0.0825907  -0.00642895   0.0305574       0.174118    -0.00441157\n",
       " -0.178941   -0.343798    -0.247018       -0.103979    -0.287277\n",
       "  0.15123    -0.053116     0.117299        0.226087    -0.0552882\n",
       "  0.142063   -0.163221     0.139257        0.232606     0.188284\n",
       "  0.192083    0.234672     0.209452    …   0.282864     0.176653\n",
       "  0.0778102  -0.0663107    0.053836        0.162325     0.167174\n",
       "  0.0454954   0.0443871    0.0486451       0.134731     0.0844227\n",
       "  0.0959006   0.160253     0.0837969       0.198073     0.205933\n",
       "  0.0971222  -0.159435     0.140663        0.1661      -0.0815373\n",
       "  0.0525798   0.0109961    0.0632148   …   0.147017    -0.213311\n",
       "  0.134512    0.200618     0.21542         0.227567    -0.131087\n",
       "  0.239254    0.11875      0.181999        0.339894     0.499974\n",
       "  ⋮                                    ⋱               \n",
       " -0.327391   -0.23864     -0.0702804      -0.175328    -0.382951\n",
       " -0.174121   -0.0826878    0.190094        0.0118228   -0.00130898\n",
       " -0.196877   -0.124513     0.00128069  …  -0.0764606   -0.147965\n",
       " -0.340936   -0.364317    -0.0592605      -0.179029    -0.506028\n",
       " -0.147382   -0.251413     0.153993        0.00878212  -0.0217106\n",
       " -0.292475   -0.135057    -0.192078       -0.141644    -0.641312\n",
       " -0.118591   -0.1164       0.0546917       0.0934055   -0.0298292\n",
       " -0.223744   -0.199653    -0.0519617   …  -0.0621597   -0.425379\n",
       " -0.210343   -0.414081    -0.0135422      -0.0766414   -0.234769\n",
       " -0.196994   -0.436368    -0.0635856      -0.0473822   -0.100775\n",
       " -0.0569767  -0.0301883    0.205285        0.0287761   -0.0592456\n",
       " -0.164617   -0.3307       0.0198128      -0.0117834   -0.247829"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = create_y(365, 1, 0, 0.1)\n",
    "X = create_ensemble_values(y, 10, 0.1, 0.15, 0.05, 0.05, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cdea879b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"150\" height=\"100\" viewBox=\"0 0 600 400\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip870\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"600\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M0 400 L600 400 L600 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip871\">\n",
       "    <rect x=\"120\" y=\"0\" width=\"421\" height=\"400\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M44.9134 371.612 L588.189 371.612 L588.189 11.811 L44.9134 11.811  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip872\">\n",
       "    <rect x=\"44\" y=\"11\" width=\"544\" height=\"361\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  59.5861,371.612 59.5861,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  200.196,371.612 200.196,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  340.806,371.612 340.806,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  481.417,371.612 481.417,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,371.612 588.189,371.612 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  59.5861,371.612 59.5861,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  200.196,371.612 200.196,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  340.806,371.612 340.806,367.294 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  481.417,371.612 481.417,367.294 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M 0 0 M59.5861 378.91 Q58.6833 378.91 58.2261 379.801 Q57.7748 380.686 57.7748 382.469 Q57.7748 384.245 58.2261 385.136 Q58.6833 386.022 59.5861 386.022 Q60.4946 386.022 60.946 385.136 Q61.4032 384.245 61.4032 382.469 Q61.4032 380.686 60.946 379.801 Q60.4946 378.91 59.5861 378.91 M59.5861 377.984 Q61.0386 377.984 61.8025 379.135 Q62.5722 380.281 62.5722 382.469 Q62.5722 384.65 61.8025 385.802 Q61.0386 386.948 59.5861 386.948 Q58.1336 386.948 57.3639 385.802 Q56.6 384.65 56.6 382.469 Q56.6 380.281 57.3639 379.135 Q58.1336 377.984 59.5861 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M192.106 385.796 L196.186 385.796 L196.186 386.78 L190.7 386.78 L190.7 385.796 Q191.365 385.108 192.511 383.95 Q193.663 382.787 193.958 382.451 Q194.519 381.821 194.739 381.386 Q194.965 380.947 194.965 380.524 Q194.965 379.836 194.479 379.402 Q193.998 378.968 193.223 378.968 Q192.673 378.968 192.06 379.158 Q191.452 379.349 190.758 379.737 L190.758 378.557 Q191.464 378.273 192.077 378.128 Q192.691 377.984 193.2 377.984 Q194.542 377.984 195.341 378.655 Q196.14 379.326 196.14 380.449 Q196.14 380.981 195.937 381.462 Q195.74 381.936 195.214 382.584 Q195.069 382.752 194.294 383.557 Q193.518 384.355 192.106 385.796 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M199.953 378.91 Q199.05 378.91 198.593 379.801 Q198.142 380.686 198.142 382.469 Q198.142 384.245 198.593 385.136 Q199.05 386.022 199.953 386.022 Q200.862 386.022 201.313 385.136 Q201.77 384.245 201.77 382.469 Q201.77 380.686 201.313 379.801 Q200.862 378.91 199.953 378.91 M199.953 377.984 Q201.406 377.984 202.17 379.135 Q202.939 380.281 202.939 382.469 Q202.939 384.65 202.17 385.802 Q201.406 386.948 199.953 386.948 Q198.501 386.948 197.731 385.802 Q196.967 384.65 196.967 382.469 Q196.967 380.281 197.731 379.135 Q198.501 377.984 199.953 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M206.707 378.91 Q205.804 378.91 205.347 379.801 Q204.895 380.686 204.895 382.469 Q204.895 384.245 205.347 385.136 Q205.804 386.022 206.707 386.022 Q207.615 386.022 208.067 385.136 Q208.524 384.245 208.524 382.469 Q208.524 380.686 208.067 379.801 Q207.615 378.91 206.707 378.91 M206.707 377.984 Q208.159 377.984 208.923 379.135 Q209.693 380.281 209.693 382.469 Q209.693 384.65 208.923 385.802 Q208.159 386.948 206.707 386.948 Q205.254 386.948 204.484 385.802 Q203.721 384.65 203.721 382.469 Q203.721 380.281 204.484 379.135 Q205.254 377.984 206.707 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M334.805 379.158 L331.854 383.771 L334.805 383.771 L334.805 379.158 M334.499 378.14 L335.969 378.14 L335.969 383.771 L337.201 383.771 L337.201 384.743 L335.969 384.743 L335.969 386.78 L334.805 386.78 L334.805 384.743 L330.905 384.743 L330.905 383.614 L334.499 378.14 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M340.968 378.91 Q340.066 378.91 339.609 379.801 Q339.157 380.686 339.157 382.469 Q339.157 384.245 339.609 385.136 Q340.066 386.022 340.968 386.022 Q341.877 386.022 342.328 385.136 Q342.786 384.245 342.786 382.469 Q342.786 380.686 342.328 379.801 Q341.877 378.91 340.968 378.91 M340.968 377.984 Q342.421 377.984 343.185 379.135 Q343.955 380.281 343.955 382.469 Q343.955 384.65 343.185 385.802 Q342.421 386.948 340.968 386.948 Q339.516 386.948 338.746 385.802 Q337.982 384.65 337.982 382.469 Q337.982 380.281 338.746 379.135 Q339.516 377.984 340.968 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M347.722 378.91 Q346.819 378.91 346.362 379.801 Q345.911 380.686 345.911 382.469 Q345.911 384.245 346.362 385.136 Q346.819 386.022 347.722 386.022 Q348.63 386.022 349.082 385.136 Q349.539 384.245 349.539 382.469 Q349.539 380.686 349.082 379.801 Q348.63 378.91 347.722 378.91 M347.722 377.984 Q349.174 377.984 349.938 379.135 Q350.708 380.281 350.708 382.469 Q350.708 384.65 349.938 385.802 Q349.174 386.948 347.722 386.948 Q346.269 386.948 345.5 385.802 Q344.736 384.65 344.736 382.469 Q344.736 380.281 345.5 379.135 Q346.269 377.984 347.722 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M474.764 381.994 Q473.977 381.994 473.514 382.532 Q473.057 383.07 473.057 384.008 Q473.057 384.94 473.514 385.484 Q473.977 386.022 474.764 386.022 Q475.552 386.022 476.009 385.484 Q476.472 384.94 476.472 384.008 Q476.472 383.07 476.009 382.532 Q475.552 381.994 474.764 381.994 M477.085 378.331 L477.085 379.396 Q476.645 379.187 476.194 379.077 Q475.748 378.968 475.308 378.968 Q474.151 378.968 473.538 379.749 Q472.93 380.53 472.843 382.11 Q473.185 381.606 473.7 381.34 Q474.215 381.068 474.834 381.068 Q476.136 381.068 476.888 381.861 Q477.646 382.648 477.646 384.008 Q477.646 385.339 476.859 386.143 Q476.072 386.948 474.764 386.948 Q473.266 386.948 472.473 385.802 Q471.68 384.65 471.68 382.469 Q471.68 380.42 472.652 379.205 Q473.624 377.984 475.262 377.984 Q475.702 377.984 476.148 378.071 Q476.599 378.157 477.085 378.331 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M481.414 378.91 Q480.511 378.91 480.054 379.801 Q479.602 380.686 479.602 382.469 Q479.602 384.245 480.054 385.136 Q480.511 386.022 481.414 386.022 Q482.322 386.022 482.774 385.136 Q483.231 384.245 483.231 382.469 Q483.231 380.686 482.774 379.801 Q482.322 378.91 481.414 378.91 M481.414 377.984 Q482.866 377.984 483.63 379.135 Q484.4 380.281 484.4 382.469 Q484.4 384.65 483.63 385.802 Q482.866 386.948 481.414 386.948 Q479.961 386.948 479.192 385.802 Q478.428 384.65 478.428 382.469 Q478.428 380.281 479.192 379.135 Q479.961 377.984 481.414 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M488.167 378.91 Q487.264 378.91 486.807 379.801 Q486.356 380.686 486.356 382.469 Q486.356 384.245 486.807 385.136 Q487.264 386.022 488.167 386.022 Q489.076 386.022 489.527 385.136 Q489.984 384.245 489.984 382.469 Q489.984 380.686 489.527 379.801 Q489.076 378.91 488.167 378.91 M488.167 377.984 Q489.62 377.984 490.384 379.135 Q491.153 380.281 491.153 382.469 Q491.153 384.65 490.384 385.802 Q489.62 386.948 488.167 386.948 Q486.715 386.948 485.945 385.802 Q485.181 384.65 485.181 382.469 Q485.181 380.281 485.945 379.135 Q486.715 377.984 488.167 377.984 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,360.936 588.189,360.936 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,300.3 588.189,300.3 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,239.663 588.189,239.663 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,179.026 588.189,179.026 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,118.39 588.189,118.39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip872)\" style=\"stroke:#000000; stroke-width:0.5; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  44.9134,57.7532 588.189,57.7532 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,371.612 44.9134,11.811 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,360.936 51.4327,360.936 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,300.3 51.4327,300.3 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,239.663 51.4327,239.663 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,179.026 51.4327,179.026 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,118.39 51.4327,118.39 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  44.9134,57.7532 51.4327,57.7532 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M 0 0 M13.0547 361.049 L20.4737 361.049 L20.4737 362.033 L13.0547 362.033 L13.0547 361.049 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M21.9436 364.273 L23.8533 364.273 L23.8533 357.681 L21.7758 358.098 L21.7758 357.033 L23.8417 356.616 L25.0107 356.616 L25.0107 364.273 L26.9204 364.273 L26.9204 365.256 L21.9436 365.256 L21.9436 364.273 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M28.1878 363.786 L29.4088 363.786 L29.4088 365.256 L28.1878 365.256 L28.1878 363.786 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M30.6878 356.616 L35.2768 356.616 L35.2768 357.6 L31.7583 357.6 L31.7583 359.718 Q32.013 359.631 32.2676 359.591 Q32.5222 359.545 32.7769 359.545 Q34.2236 359.545 35.0685 360.337 Q35.9134 361.13 35.9134 362.484 Q35.9134 363.879 35.0454 364.655 Q34.1773 365.424 32.5975 365.424 Q32.0535 365.424 31.4864 365.332 Q30.925 365.239 30.3232 365.054 L30.3232 363.879 Q30.844 364.163 31.3996 364.302 Q31.9551 364.44 32.5743 364.44 Q33.5755 364.44 34.16 363.914 Q34.7444 363.387 34.7444 362.484 Q34.7444 361.582 34.16 361.055 Q33.5755 360.528 32.5743 360.528 Q32.1056 360.528 31.6368 360.633 Q31.1739 360.737 30.6878 360.957 L30.6878 356.616 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M12.8059 300.413 L20.2248 300.413 L20.2248 301.396 L12.8059 301.396 L12.8059 300.413 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M21.6947 303.636 L23.6045 303.636 L23.6045 297.045 L21.5269 297.461 L21.5269 296.396 L23.5929 295.98 L24.7619 295.98 L24.7619 303.636 L26.6716 303.636 L26.6716 304.62 L21.6947 304.62 L21.6947 303.636 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M27.9389 303.15 L29.16 303.15 L29.16 304.62 L27.9389 304.62 L27.9389 303.15 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M32.9273 296.749 Q32.0245 296.749 31.5674 297.641 Q31.116 298.526 31.116 300.308 Q31.116 302.085 31.5674 302.976 Q32.0245 303.862 32.9273 303.862 Q33.8359 303.862 34.2873 302.976 Q34.7444 302.085 34.7444 300.308 Q34.7444 298.526 34.2873 297.641 Q33.8359 296.749 32.9273 296.749 M32.9273 295.824 Q34.3799 295.824 35.1437 296.975 Q35.9134 298.121 35.9134 300.308 Q35.9134 302.49 35.1437 303.642 Q34.3799 304.788 32.9273 304.788 Q31.4748 304.788 30.7051 303.642 Q29.9412 302.49 29.9412 300.308 Q29.9412 298.121 30.7051 296.975 Q31.4748 295.824 32.9273 295.824 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M12.748 239.776 L20.167 239.776 L20.167 240.76 L12.748 240.76 L12.748 239.776 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M23.9343 236.113 Q23.0315 236.113 22.5744 237.004 Q22.123 237.889 22.123 239.672 Q22.123 241.448 22.5744 242.34 Q23.0315 243.225 23.9343 243.225 Q24.8429 243.225 25.2943 242.34 Q25.7514 241.448 25.7514 239.672 Q25.7514 237.889 25.2943 237.004 Q24.8429 236.113 23.9343 236.113 M23.9343 235.187 Q25.3869 235.187 26.1507 236.338 Q26.9204 237.484 26.9204 239.672 Q26.9204 241.853 26.1507 243.005 Q25.3869 244.151 23.9343 244.151 Q22.4818 244.151 21.7121 243.005 Q20.9482 241.853 20.9482 239.672 Q20.9482 237.484 21.7121 236.338 Q22.4818 235.187 23.9343 235.187 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M28.1878 242.513 L29.4088 242.513 L29.4088 243.983 L28.1878 243.983 L28.1878 242.513 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M30.6878 235.343 L35.2768 235.343 L35.2768 236.327 L31.7583 236.327 L31.7583 238.445 Q32.013 238.358 32.2676 238.318 Q32.5222 238.271 32.7769 238.271 Q34.2236 238.271 35.0685 239.064 Q35.9134 239.857 35.9134 241.211 Q35.9134 242.606 35.0454 243.381 Q34.1773 244.151 32.5975 244.151 Q32.0535 244.151 31.4864 244.058 Q30.925 243.966 30.3232 243.781 L30.3232 242.606 Q30.844 242.889 31.3996 243.028 Q31.9551 243.167 32.5743 243.167 Q33.5755 243.167 34.16 242.641 Q34.7444 242.114 34.7444 241.211 Q34.7444 240.308 34.16 239.782 Q33.5755 239.255 32.5743 239.255 Q32.1056 239.255 31.6368 239.359 Q31.1739 239.463 30.6878 239.683 L30.6878 235.343 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M23.6855 175.476 Q22.7827 175.476 22.3255 176.367 Q21.8741 177.253 21.8741 179.035 Q21.8741 180.812 22.3255 181.703 Q22.7827 182.588 23.6855 182.588 Q24.594 182.588 25.0454 181.703 Q25.5026 180.812 25.5026 179.035 Q25.5026 177.253 25.0454 176.367 Q24.594 175.476 23.6855 175.476 M23.6855 174.55 Q25.138 174.55 25.9019 175.702 Q26.6716 176.848 26.6716 179.035 Q26.6716 181.217 25.9019 182.368 Q25.138 183.514 23.6855 183.514 Q22.2329 183.514 21.4633 182.368 Q20.6994 181.217 20.6994 179.035 Q20.6994 176.848 21.4633 175.702 Q22.2329 174.55 23.6855 174.55 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M27.9389 181.877 L29.16 181.877 L29.16 183.346 L27.9389 183.346 L27.9389 181.877 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M32.9273 175.476 Q32.0245 175.476 31.5674 176.367 Q31.116 177.253 31.116 179.035 Q31.116 180.812 31.5674 181.703 Q32.0245 182.588 32.9273 182.588 Q33.8359 182.588 34.2873 181.703 Q34.7444 180.812 34.7444 179.035 Q34.7444 177.253 34.2873 176.367 Q33.8359 175.476 32.9273 175.476 M32.9273 174.55 Q34.3799 174.55 35.1437 175.702 Q35.9134 176.848 35.9134 179.035 Q35.9134 181.217 35.1437 182.368 Q34.3799 183.514 32.9273 183.514 Q31.4748 183.514 30.7051 182.368 Q29.9412 181.217 29.9412 179.035 Q29.9412 176.848 30.7051 175.702 Q31.4748 174.55 32.9273 174.55 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M23.9343 114.84 Q23.0315 114.84 22.5744 115.731 Q22.123 116.616 22.123 118.399 Q22.123 120.175 22.5744 121.066 Q23.0315 121.952 23.9343 121.952 Q24.8429 121.952 25.2943 121.066 Q25.7514 120.175 25.7514 118.399 Q25.7514 116.616 25.2943 115.731 Q24.8429 114.84 23.9343 114.84 M23.9343 113.914 Q25.3869 113.914 26.1507 115.065 Q26.9204 116.211 26.9204 118.399 Q26.9204 120.58 26.1507 121.732 Q25.3869 122.878 23.9343 122.878 Q22.4818 122.878 21.7121 121.732 Q20.9482 120.58 20.9482 118.399 Q20.9482 116.211 21.7121 115.065 Q22.4818 113.914 23.9343 113.914 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M28.1878 121.24 L29.4088 121.24 L29.4088 122.71 L28.1878 122.71 L28.1878 121.24 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M30.6878 114.07 L35.2768 114.07 L35.2768 115.054 L31.7583 115.054 L31.7583 117.172 Q32.013 117.085 32.2676 117.044 Q32.5222 116.998 32.7769 116.998 Q34.2236 116.998 35.0685 117.791 Q35.9134 118.584 35.9134 119.938 Q35.9134 121.333 35.0454 122.108 Q34.1773 122.878 32.5975 122.878 Q32.0535 122.878 31.4864 122.785 Q30.925 122.692 30.3232 122.507 L30.3232 121.333 Q30.844 121.616 31.3996 121.755 Q31.9551 121.894 32.5743 121.894 Q33.5755 121.894 34.16 121.367 Q34.7444 120.841 34.7444 119.938 Q34.7444 119.035 34.16 118.508 Q33.5755 117.982 32.5743 117.982 Q32.1056 117.982 31.6368 118.086 Q31.1739 118.19 30.6878 118.41 L30.6878 114.07 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M21.6947 61.0894 L23.6045 61.0894 L23.6045 54.498 L21.5269 54.9147 L21.5269 53.8499 L23.5929 53.4332 L24.7619 53.4332 L24.7619 61.0894 L26.6716 61.0894 L26.6716 62.0732 L21.6947 62.0732 L21.6947 61.0894 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M27.9389 60.6033 L29.16 60.6033 L29.16 62.0732 L27.9389 62.0732 L27.9389 60.6033 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M32.9273 54.2029 Q32.0245 54.2029 31.5674 55.0941 Q31.116 55.9795 31.116 57.7619 Q31.116 59.5385 31.5674 60.4297 Q32.0245 61.3151 32.9273 61.3151 Q33.8359 61.3151 34.2873 60.4297 Q34.7444 59.5385 34.7444 57.7619 Q34.7444 55.9795 34.2873 55.0941 Q33.8359 54.2029 32.9273 54.2029 M32.9273 53.2769 Q34.3799 53.2769 35.1437 54.4286 Q35.9134 55.5744 35.9134 57.7619 Q35.9134 59.9436 35.1437 61.0952 Q34.3799 62.241 32.9273 62.241 Q31.4748 62.241 30.7051 61.0952 Q29.9412 59.9436 29.9412 57.7619 Q29.9412 55.5744 30.7051 54.4286 Q31.4748 53.2769 32.9273 53.2769 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip872)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  60.2891,219.287 60.9922,179.561 61.6952,213.866 62.3983,185.731 63.1013,156.193 63.8044,157.603 64.5074,158.753 65.2105,168.788 65.9135,154.052 66.6166,188.915 \n",
       "  67.3196,204.895 68.0227,194.924 68.7258,118.393 69.4288,180.429 70.1319,89.2534 70.8349,146.441 71.538,195.131 72.241,124.308 72.9441,139.563 73.6471,130.02 \n",
       "  74.3502,151.138 75.0532,130.468 75.7563,118.799 76.4593,139.288 77.1624,89.4056 77.8654,128.719 78.5685,99.1174 79.2715,113.808 79.9746,154.739 80.6776,110.778 \n",
       "  81.3807,134.517 82.0837,130.74 82.7868,129.39 83.4898,123.351 84.1929,136.914 84.8959,96.0593 85.599,86.1139 86.302,131.217 87.0051,136.46 87.7081,122.381 \n",
       "  88.4112,109.884 89.1142,82.6411 89.8173,86.3631 90.5203,77.515 91.2234,109.541 91.9264,99.2248 92.6295,95.4754 93.3325,88.235 94.0356,73.5416 94.7386,87.0899 \n",
       "  95.4417,104.572 96.1447,113.027 96.8478,93.4361 97.5508,109.076 98.2539,84.5624 98.9569,98.8401 99.66,82.5419 100.363,70.4166 101.066,70.5735 101.769,99.095 \n",
       "  102.472,107.59 103.175,95.1955 103.878,58.3857 104.581,71.6737 105.284,44.4712 105.987,36.45 106.691,74.6932 107.394,75.8478 108.097,66.8182 108.8,82.3018 \n",
       "  109.503,55.5796 110.206,37.1092 110.909,73.3569 111.612,67.9295 112.315,73.0949 113.018,47.8136 113.721,62.5421 114.424,49.7968 115.127,72.9761 115.83,32.3615 \n",
       "  116.533,34.3876 117.236,74.9817 117.939,92.6261 118.642,34.7283 119.345,75.3795 120.048,89.3863 120.752,87.858 121.455,81.0603 122.158,64.1888 122.861,67.9044 \n",
       "  123.564,73.5071 124.267,52.492 124.97,67.037 125.673,74.1935 126.376,83.2596 127.079,62.3275 127.782,65.2296 128.485,34.3467 129.188,60.7954 129.891,45.8442 \n",
       "  130.594,45.4722 131.297,52.1963 132,69.8737 132.703,86.5012 133.406,23.4067 134.109,109.747 134.813,109.906 135.516,78.7182 136.219,68.262 136.922,71.396 \n",
       "  137.625,62.8143 138.328,34.13 139.031,72.2228 139.734,69.2099 140.437,49.3972 141.14,59.5336 141.843,86.9243 142.546,68.4965 143.249,80.5137 143.952,73.8558 \n",
       "  144.655,48.1462 145.358,72.736 146.061,51.8914 146.764,88.0446 147.467,48.4632 148.171,76.7327 148.874,73.4464 149.577,107.934 150.28,75.802 150.983,88.9185 \n",
       "  151.686,110.516 152.389,109.621 153.092,103.903 153.795,111.508 154.498,92.9255 155.201,94.8802 155.904,110.246 156.607,127.676 157.31,145.439 158.013,115.39 \n",
       "  158.716,100.306 159.419,97.4217 160.122,124.913 160.825,98.3535 161.528,74.9183 162.232,134.235 162.935,103.598 163.638,101.442 164.341,128.242 165.044,122.357 \n",
       "  165.747,152.409 166.45,152.904 167.153,125.35 167.856,118.237 168.559,114.025 169.262,145.198 169.965,135.682 170.668,143.321 171.371,122.69 172.074,151.78 \n",
       "  172.777,166.324 173.48,129.628 174.183,133.881 174.886,146.209 175.589,147.195 176.293,165.496 176.996,146.139 177.699,171.941 178.402,164.31 179.105,133.004 \n",
       "  179.808,150.346 180.511,144.249 181.214,180.838 181.917,202.619 182.62,191.333 183.323,183.172 184.026,160.789 184.729,141.26 185.432,188.997 186.135,162.214 \n",
       "  186.838,163.369 187.541,180.543 188.244,184.228 188.947,174.157 189.651,170.831 190.354,198.794 191.057,165.391 191.76,172.256 192.463,195.258 193.166,167.16 \n",
       "  193.869,197.021 194.572,217.455 195.275,202.351 195.978,197.939 196.681,258.078 197.384,198.775 198.087,230.097 198.79,229.841 199.493,214.376 200.196,208.599 \n",
       "  200.899,219.512 201.602,207.271 202.305,212.377 203.008,236.436 203.712,244.255 204.415,225.072 205.118,252.118 205.821,241.585 206.524,220.849 207.227,238.327 \n",
       "  207.93,235.119 208.633,241.66 209.336,252.364 210.039,262.322 210.742,250.611 211.445,271.055 212.148,278.124 212.851,239.683 213.554,266.505 214.257,267.365 \n",
       "  214.96,293.003 215.663,239.539 216.366,249.553 217.069,287.569 217.773,284.795 218.476,268.821 219.179,250.339 219.882,265.395 220.585,276.117 221.288,297.422 \n",
       "  221.991,287.713 222.694,288.519 223.397,295.257 224.1,289.922 224.803,270.122 225.506,272.618 226.209,287.97 226.912,288.549 227.615,274.569 228.318,314.062 \n",
       "  229.021,287.414 229.724,310.52 230.427,306.176 231.131,279.539 231.834,297.36 232.537,310.42 233.24,293.333 233.943,323.049 234.646,304.668 235.349,296.01 \n",
       "  236.052,292.548 236.755,260.519 237.458,295.082 238.161,278.337 238.864,313.921 239.567,294.807 240.27,313.897 240.973,303.783 241.676,312.319 242.379,307.314 \n",
       "  243.082,272.129 243.785,310.161 244.488,316.399 245.192,312.545 245.895,320.674 246.598,254.836 247.301,285.982 248.004,283.968 248.707,305.983 249.41,314.452 \n",
       "  250.113,290.171 250.816,322.02 251.519,288.442 252.222,308.682 252.925,279.446 253.628,280.635 254.331,299.583 255.034,314.851 255.737,286.414 256.44,312.221 \n",
       "  257.143,283.021 257.846,304.968 258.549,291.694 259.253,289.345 259.956,324.47 260.659,282.604 261.362,323.348 262.065,305.545 262.768,320.948 263.471,311.192 \n",
       "  264.174,325.728 264.877,277.635 265.58,296.838 266.283,340.587 266.986,314.308 267.689,273.558 268.392,294.653 269.095,280.398 269.798,288.604 270.501,267.119 \n",
       "  271.204,320.856 271.907,313.609 272.611,319.16 273.314,303.092 274.017,286.981 274.72,293.339 275.423,316.214 276.126,264.043 276.829,309.95 277.532,274.093 \n",
       "  278.235,241.833 278.938,287.166 279.641,283.024 280.344,231.57 281.047,259.453 281.75,249.357 282.453,263.365 283.156,228.959 283.859,249.84 284.562,261.295 \n",
       "  285.265,282.977 285.968,286.981 286.672,265.786 287.375,289.774 288.078,269.45 288.781,254.443 289.484,242.944 290.187,248.261 290.89,267.148 291.593,259.274 \n",
       "  292.296,250.911 292.999,256.217 293.702,268.65 294.405,259.127 295.108,240.713 295.811,223.372 296.514,237.954 297.217,233.122 297.92,247.093 298.623,244.944 \n",
       "  299.326,235.013 300.03,220.604 300.733,275.85 301.436,228.558 302.139,205.975 302.842,203.737 303.545,248.573 304.248,202.839 304.951,249.788 305.654,213.7 \n",
       "  306.357,204.601 307.06,184.574 307.763,192.72 308.466,218.986 309.169,240.446 309.872,197.86 310.575,208.454 311.278,226.87 311.981,220.297 312.684,196.538 \n",
       "  313.387,213.614 314.091,202.483 314.794,173.399 315.497,204.912 316.2,208.488 316.903,169.191 317.606,196.696 318.309,187.506 319.012,175.007 319.715,135.224 \n",
       "  320.418,190.963 321.121,196.616 321.824,187.702 322.527,180.445 323.23,166.868 323.933,144.799 324.636,174.906 325.339,165.718 326.042,155.858 326.745,146.349 \n",
       "  327.448,163 328.152,177.367 328.855,141.04 329.558,163.95 330.261,121.561 330.964,139.451 331.667,137.787 332.37,112.747 333.073,145.016 333.776,117.683 \n",
       "  334.479,122.96 335.182,157.588 335.885,154.12 336.588,127.355 337.291,120.314 337.994,104.663 338.697,132.195 339.4,125.034 340.103,139.736 340.806,93.8623 \n",
       "  341.51,121.932 342.213,120.382 342.916,134.517 343.619,101.799 344.322,113.767 345.025,109.891 345.728,67.7395 346.431,102.656 347.134,96.4066 347.837,70.0177 \n",
       "  348.54,102.941 349.243,101.056 349.946,116.064 350.649,124.99 351.352,129.532 352.055,82.5439 352.758,90.5166 353.461,120.476 354.164,88.275 354.867,92.2706 \n",
       "  355.571,59.8298 356.274,106.391 356.977,95.8845 357.68,55.1199 358.383,98.5224 359.086,61.3631 359.789,72.5047 360.492,91.9311 361.195,61.2649 361.898,46.7561 \n",
       "  362.601,63.8954 363.304,61.4156 364.007,95.6094 364.71,52.4902 365.413,61.5197 366.116,47.146 366.819,47.4972 367.522,63.6202 368.225,61.5819 368.928,63.3075 \n",
       "  369.632,35.8739 370.335,92.1253 371.038,74.4293 371.741,64.0406 372.444,89.1533 373.147,52.9975 373.85,68.877 374.553,99.3704 375.256,71.3142 375.959,64.0019 \n",
       "  376.662,71.438 377.365,89.2818 378.068,49.6167 378.771,82.5467 379.474,62.4925 380.177,92.0458 380.88,82.8214 381.583,68.5425 382.286,76.4579 382.99,81.5076 \n",
       "  383.693,33.4116 384.396,21.9941 385.099,60.6497 385.802,61.5797 386.505,47.3455 387.208,77.3897 387.911,72.349 388.614,52.5304 389.317,58.2514 390.02,68.8517 \n",
       "  390.723,36.1658 391.426,89.9931 392.129,64.6743 392.832,87.3633 393.535,80.4606 394.238,62.9059 394.941,100.519 395.644,69.5119 396.347,56.7954 397.051,66.3957 \n",
       "  397.754,60.5911 398.457,99.5143 399.16,68.8589 399.863,72.3423 400.566,80.9405 401.269,117.248 401.972,81.7077 402.675,84.867 403.378,79.0306 404.081,72.5274 \n",
       "  404.784,69.6097 405.487,78.7406 406.19,52.6239 406.893,91.694 407.596,113.448 408.299,51.3523 409.002,108.756 409.705,106.461 410.408,93.4578 411.112,68.4232 \n",
       "  411.815,122.271 412.518,109.386 413.221,92.068 413.924,97.1263 414.627,125.113 415.33,109.967 416.033,121.681 416.736,100.647 417.439,107.856 418.142,127.129 \n",
       "  418.845,102.041 419.548,109.162 420.251,63.2018 420.954,126.645 421.657,117.438 422.36,145.331 423.063,128.038 423.766,149.092 424.47,113.9 425.173,151.962 \n",
       "  425.876,127.842 426.579,129.433 427.282,123.825 427.985,157.044 428.688,157.601 429.391,161.949 430.094,157.478 430.797,150.006 431.5,165.359 432.203,111.67 \n",
       "  432.906,143.07 433.609,137.927 434.312,158.076 435.015,161.2 435.718,195.004 436.421,172.429 437.124,155.427 437.827,199.692 438.531,152.767 439.234,172.145 \n",
       "  439.937,167.86 440.64,162.704 441.343,169.379 442.046,204.804 442.749,187.121 443.452,186.171 444.155,188.541 444.858,173.95 445.561,174.57 446.264,210.989 \n",
       "  446.967,201.6 447.67,228.671 448.373,156.562 449.076,223.882 449.779,235.98 450.482,208.128 451.185,218.263 451.888,209.149 452.592,196.325 453.295,195.233 \n",
       "  453.998,210.953 454.701,211.484 455.404,185.646 456.107,231.15 456.81,227.643 457.513,246.622 458.216,214.054 458.919,239.983 459.622,211.806 460.325,251.928 \n",
       "  461.028,237.538 461.731,209.109 462.434,234.737 463.137,227.207 463.84,272.438 464.543,278.113 465.246,241.365 465.95,234.515 466.653,232.803 467.356,206.9 \n",
       "  468.059,270.504 468.762,242.65 469.465,272.417 470.168,256.27 470.871,274.925 471.574,272.291 472.277,268.081 472.98,304.871 473.683,254.539 474.386,237.467 \n",
       "  475.089,250.815 475.792,289.53 476.495,257.643 477.198,234.511 477.901,269.906 478.604,284.938 479.307,318.824 480.011,269.011 480.714,299.341 481.417,293.651 \n",
       "  482.12,265.703 482.823,302.266 483.526,307.264 484.229,274.551 484.932,245.191 485.635,296.2 486.338,271.395 487.041,295.737 487.744,287.509 488.447,276.625 \n",
       "  489.15,268.883 489.853,301.936 490.556,271.197 491.259,274.596 491.962,253.976 492.665,290.482 493.369,322.188 494.072,311.33 494.775,287.233 495.478,275.449 \n",
       "  496.181,287.601 496.884,323.463 497.587,287.797 498.29,296.444 498.993,347.25 499.696,280.449 500.399,300.381 501.102,334.059 501.805,317.88 502.508,314.053 \n",
       "  503.211,328.342 503.914,299.631 504.617,286.646 505.32,327.722 506.023,289.308 506.726,320.304 507.43,315.81 508.133,330.89 508.836,291.806 509.539,281.394 \n",
       "  510.242,301.683 510.945,334.47 511.648,291.032 512.351,331.999 513.054,309.018 513.757,340.073 514.46,282.098 515.163,294.964 515.866,279.237 516.569,312.014 \n",
       "  517.272,342.602 517.975,309.95 518.678,280.429 519.381,349.488 520.084,319.114 520.787,300 521.491,361.429 522.194,332.413 522.897,275.622 523.6,305.103 \n",
       "  524.303,316.963 525.006,291.554 525.709,300.113 526.412,317.024 527.115,285.614 527.818,317.639 528.521,267.885 529.224,260.752 529.927,272.168 530.63,283.126 \n",
       "  531.333,313.48 532.036,283.094 532.739,290.876 533.442,305.062 534.145,276.523 534.849,283.812 535.552,303.009 536.255,280.594 536.958,280.935 537.661,286.163 \n",
       "  538.364,269.339 539.067,289.393 539.77,258.508 540.473,216.104 541.176,253.381 541.879,249.288 542.582,268.97 543.285,321.424 543.988,257.953 544.691,256.965 \n",
       "  545.394,282.793 546.097,261.762 546.8,280.189 547.503,230.896 548.206,244.947 548.91,240.409 549.613,274.18 550.316,267.992 551.019,258.02 551.722,254.035 \n",
       "  552.425,214.209 553.128,248.15 553.831,260.205 554.534,254.776 555.237,275.937 555.94,209.017 556.643,242.566 557.346,238.699 558.049,222.159 558.752,222.665 \n",
       "  559.455,238.254 560.158,209.154 560.861,219.211 561.564,226.531 562.267,239.293 562.971,193.849 563.674,193.137 564.377,233.218 565.08,225.468 565.783,179.185 \n",
       "  566.486,196.971 567.189,240.394 567.892,181.659 568.595,256.8 569.298,182.644 570.001,230.614 570.704,207.498 571.407,191.248 572.11,186.211 572.813,209.081 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"\n",
       "M496.961 54.0444 L570.08 54.0444 L570.08 23.8044 L496.961 23.8044  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#000000; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  496.961,54.0444 570.08,54.0444 570.08,23.8044 496.961,23.8044 496.961,54.0444 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip870)\" style=\"stroke:#009af9; stroke-width:1; stroke-opacity:1; fill:none\" points=\"\n",
       "  502.998,38.9244 539.216,38.9244 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip870)\" d=\"M 0 0 M548.713 43.8462 Q548.262 45.0036 547.833 45.3566 Q547.405 45.7097 546.688 45.7097 L545.837 45.7097 L545.837 44.8185 L546.462 44.8185 Q546.902 44.8185 547.145 44.6101 Q547.388 44.4018 547.683 43.6263 L547.874 43.1402 L545.252 36.7629 L546.381 36.7629 L548.406 41.8324 L550.432 36.7629 L551.56 36.7629 L548.713 43.8462 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip870)\" d=\"M 0 0 M553.03 42.2606 L554.94 42.2606 L554.94 35.6692 L552.862 36.0859 L552.862 35.0211 L554.928 34.6044 L556.097 34.6044 L556.097 42.2606 L558.007 42.2606 L558.007 43.2444 L553.03 43.2444 L553.03 42.2606 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(X[:,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80b7ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5-element Vector{Float64}:\n",
       " -0.09920110878975748\n",
       " -0.0032894391110474402\n",
       " -0.027415657290163778\n",
       "  0.027191886937924348\n",
       " -0.07305983913099548"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "biases = rand(d, p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d6222e",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dcaee2c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: @add_arg_table! not defined\nin expression starting at In[55]:4",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: @add_arg_table! not defined\nin expression starting at In[55]:4",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ :0",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "function eval_method(args, X, y, y_true, split_, past, num_past, val, mean_y, std_y)\n",
    "\n",
    "    n, p = size(X)\n",
    "    split_index = floor(Int,n*split_)\n",
    "    if val == -1\n",
    "        val = size(X)[1]\n",
    "    end\n",
    "\n",
    "    X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, max(split_index-num_past*past+1, 1), min(num_past*past, split_index), val, args[\"uncertainty\"], args[\"last_yT\"])\n",
    "    println(\"There are \", size(X)[1], \" samples in total.\")\n",
    "    println(\"We start training at index \", max(split_index-num_past*past+1, 1))\n",
    "    println(\"We test between index \", max(split_index-num_past*past+1, 1)+1+min(num_past*past, split_index), \" and \",  max(split_index-num_past*past+1, 1)+1+min(num_past*past, split_index)+val+1)\n",
    "\n",
    "    β_list0 = zeros(val, p)\n",
    "    β_listt = zeros(val, p)\n",
    "    β_listl2 = zeros(val, p)\n",
    "\n",
    "    β_l2_init = l2_regression(X0,y0,args[\"rho\"], 0); #0 is for beta_stat which I removed\n",
    "\n",
    "    #β_list_linear_adaptive_pure_Vt = zeros(val, p)\n",
    "    β_list_linear_adaptive_trained_one = zeros(val, p)\n",
    "    β_list_linear_adaptive_trained_one_standard = zeros(val, p)\n",
    "\n",
    "    β_list_linear_adaptive_trained_one_err_rule = zeros(val, p)\n",
    "    β_list_linear_adaptive_trained_one_standard_err_rule = zeros(val, p)\n",
    "\n",
    "\n",
    "    #_, β0_0, V0_0, _ = adaptive_ridge_regression_exact_no_stable(vcat(X0,Xt), vcat(y0,yt), ρ, ρ, past)\n",
    "    args[\"err_rule\"] = false\n",
    "    _, β0_0, V0_0, _ = adaptive_ridge_regression_exact_no_stable(args, X0, y0, args[\"rho_beta\"], args[\"rho\"], args[\"rho_V\"], past)\n",
    "    _, β0_1, V0_1 = adaptive_ridge_regression_exact_no_stable(args, X0, y0, 0, args[\"rho\"], args[\"rho_V\"], past)\n",
    "\n",
    "    #We use the error instead of the forecasts.\n",
    "    args[\"err_rule\"] = true\n",
    "    _, β0_0_err_rule, V0_0_err_rule, _ = adaptive_ridge_regression_exact_no_stable(args, X0, y0, args[\"rho_beta\"], args[\"rho\"], args[\"rho_V\"], past)\n",
    "    _, β0_1_err_rule, V0_1_err_rule, _ = adaptive_ridge_regression_exact_no_stable(args, X0, y0, 0, args[\"rho\"], args[\"rho_V\"], past)\n",
    "    #_, β0_1, V0_1 = adaptive_ridge_regression_standard(args, X0, y0, args[\"rho\"], args[\"rho_V\"], past)\n",
    "\n",
    "    #TODO: Uncomment\n",
    "    #obj, β_linear_adaptive_pure_0_Vt, Vt_adaptive_pure, _ = adaptive_ridge_regression_exact_Vt(vcat(X0,Xt), vcat(y0,yt), ρ, ρ, past, 1)\n",
    "\n",
    "    β_list_bandits_t = zeros(val, p-1)\n",
    "    β_list_bandits_all = zeros(val, p-1)\n",
    "    β_list_PA = zeros(val, p)\n",
    "    #IMPORTANT: We initialize with equal weights but we could also initialize with l2 weights\n",
    "    β_PA = ones(p)/(p)#β_l2_init[2:end]\n",
    "    println(\"Optimization finished. Evaluation starts.\")\n",
    "\n",
    "    last_timesteps = zeros(val)\n",
    "\n",
    "    for s=1:val\n",
    "\n",
    "        #TODO check split_index with max(split inex, 1)\n",
    "        if args[\"more_data_for_beta0\"]\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, max(split_index-num_past*past+1, 1), s+(num_past-1)*past, past-1, args[\"uncertainty\"], args[\"last_yT\"])\n",
    "        else\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, max(s+split_index-num_past*past+1, 1), (num_past-1)*past, past-1, args[\"uncertainty\"], args[\"last_yT\"])\n",
    "        end\n",
    "\n",
    "        #TODO: evaluate also if we change Vt regularly\n",
    "        #obj, β_linear_adaptive_pure_0_Vt, Vt_adaptive_pure, _ = adaptive_ridge_regression_exact_Vt(vcat(X0,Xt), vcat(y0,yt), ρ, ρ, past, 1)\n",
    "\n",
    "\n",
    "        #Line to get Z_{t+1}\n",
    "        X_for_Z = X[split_index-past+s+1:split_index+s+1,:]\n",
    "        X_for_Z[:,1] .= 1\n",
    "        y_for_Z = y[split_index-past+s+1:split_index+s+1,:]\n",
    "\n",
    "        args[\"err_rule\"] = false\n",
    "        X_, Z_test, y_ = get_X_Z_y(args, X_for_Z, y_for_Z, past)\n",
    "        args[\"err_rule\"] = true\n",
    "        _, Z_test_err_rule, _ = get_X_Z_y(args, X_for_Z, y_for_Z, past)\n",
    "\n",
    "        #BASELINES\n",
    "        β_list_bandits_all[s,:] = compute_bandit_weights(vcat(X0,Xt)[:,2:end], vcat(y0,yt))\n",
    "        β_list_bandits_t[s,:] = compute_bandit_weights(Xt[:,2:end], yt)\n",
    "        β_PA = compute_PA_weights(0.01, β_PA, Matrix(Xt)[end,1:end], yt[end])\n",
    "        β_list_PA[s,:] = β_PA\n",
    "        #β_l2 = l2_regression(vcat(X0,Xt),vcat(y0,yt),ρ);\n",
    "        #β_listl2[s,:] = β_l2\n",
    "\n",
    "        #TODO Add if needed\n",
    "        #β_list_linear_adaptive_pure_Vt[s,:] = β_linear_adaptive_pure_0_Vt + Vt_adaptive_pure[end,:,:] * Z_test[1,:]\n",
    "        β_list_linear_adaptive_trained_one[s,:] = β0_0 + V0_0 * Z_test[1,:]\n",
    "        β_list_linear_adaptive_trained_one_standard[s,:] = β0_1 + V0_1 * Z_test[1, :]\n",
    "\n",
    "        β_list_linear_adaptive_trained_one_err_rule[s,:] = β0_0_err_rule + V0_0_err_rule * Z_test_err_rule[1,:]\n",
    "        β_list_linear_adaptive_trained_one_standard_err_rule[s,:] = β0_1_err_rule + V0_1_err_rule * Z_test_err_rule[1, :]\n",
    "\n",
    "        last_timesteps[s] = Z_test[1,end]\n",
    "    end\n",
    "\n",
    "    #TODO Best underlying model\n",
    "    println(\"Evaluation finished. Metrics start.\")\n",
    "    X0, y0, Xt, yt, _, D_min, D_max = prepare_data_from_y(X, y, 1, split_index, val, args[\"uncertainty\"], args[\"last_yT\"])\n",
    "    _, _, _, _, yt_true, _, _ = prepare_data_from_y(X, y_true, 1, split_index, val, args[\"uncertainty\"], args[\"last_yT\"])\n",
    "\n",
    "    # Unstandardize for metrics\n",
    "    yt_true = yt_true.*std_y.+mean_y\n",
    "\n",
    "    # Unstandardize predictions as well\n",
    "    # The reason why we put 2:end is because the first element is the intercept term (1)\n",
    "    err_mean = [abs(yt_true[s]-(mean(Xt[s,2:end]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_last_timestep = [abs(yt_true[s]-(last_timesteps[s].*std_y.+mean_y)) for s=2:val]\n",
    "    err_best_model = get_best_model_errors(yt_true, Xt, mean_y, std_y)\n",
    "    err_bandit_full = [abs(yt_true[s]-(dot(Xt[s,2:end],β_list_bandits_all[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_bandit_t = [abs(yt_true[s]-(dot(Xt[s,2:end],β_list_bandits_t[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_PA = [abs(yt_true[s]-(dot(Xt[s,1:end],β_list_PA[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_baseline = [abs(yt_true[s]-(dot(Xt[s,:],β_l2_init).*std_y.+mean_y)) for s=1:val]\n",
    "    #err_l2 = [abs(yt_true[s]-dot(Xt[s,:],β_listl2[s,:])) for s=1:val]\n",
    "\n",
    "    #TODO: Uncomment\n",
    "    #err_linear_adaptive_pure_Vt = [abs(yt_true[s]-dot(Xt[s,:],β_list_linear_adaptive_pure_Vt[s,:])) for s=1:val]\n",
    "    err_linear_adaptive_trained_one = [abs(yt_true[s]-(dot(Xt[s,:],β_list_linear_adaptive_trained_one[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_linear_adaptive_trained_one_standard = [abs(yt_true[s]-(dot(Xt[s,:],β_list_linear_adaptive_trained_one_standard[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "\n",
    "    err_linear_adaptive_trained_one_err_rule = [abs(yt_true[s]-(dot(Xt[s,:],β_list_linear_adaptive_trained_one_err_rule[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "    err_linear_adaptive_trained_one_standard_err_rule = [abs(yt_true[s]-(dot(Xt[s,:],β_list_linear_adaptive_trained_one_standard_err_rule[s,:]).*std_y.+mean_y)) for s=1:val]\n",
    "\n",
    "    #TODO check get_metrics\n",
    "    println(\"\\n### Mean Baseline ###\")\n",
    "    get_metrics(args, \"mean\", err_mean, yt_true)\n",
    "\n",
    "    println(\"\\n### Last Timestep Baseline ###\")\n",
    "    get_metrics(args, \"last_timestep\", err_last_timestep, yt_true[2:end])\n",
    "\n",
    "    println(\"\\n### Best Model Baseline ###\")\n",
    "    get_metrics(args, \"best_model\", err_best_model, yt_true)\n",
    "\n",
    "    println(\"\\n### Bandits Full Baseline ###\")\n",
    "    get_metrics(args, \"bandits_full\", err_bandit_full, yt_true)\n",
    "\n",
    "    println(\"\\n### Bandits Only Last T Baseline ###\")\n",
    "    get_metrics(args, \"bandits_recent\", err_bandit_t, yt_true)\n",
    "\n",
    "    println(\"\\n### Passive-Aggressive Baseline ###\")\n",
    "    ### The Beta 0 that is originating from the adaptive formulation\n",
    "    get_metrics(args, \"PA\", err_PA, yt_true)\n",
    "\n",
    "    println(\"\\n### β0 Baseline ###\")\n",
    "    get_metrics(args, \"ridge\", err_baseline, yt_true)\n",
    "\n",
    "#     println(\"\\n### β0 Baseline Retrained ###\")\n",
    "#     get_metrics(err_l2, yt_true)\n",
    "\n",
    "    #TODO: Uncomment\n",
    "#     println(\"\\n### βt Linear Decision Rule Adaptive with NO Stable Part Vt ###\")\n",
    "#     ### Using Beta t+1 = Beta 0 + V0*Z_{t+1}, with Beta 0, V0 that is originating from the linear adaptive formulation with NO stable part\n",
    "#     get_metrics(err_linear_adaptive_pure_Vt, yt_true)\n",
    "\n",
    "    println(\"\\n### βt Linear Decision Rule Adaptive with NO Stable Part and Trained ONCE ###\")\n",
    "    ### Using Beta t+1 = Beta 0 + V0*Z_{t+1}, with Beta 0, V0 that is originating from the linear adaptive formulation with NO stable part\n",
    "    get_metrics(args, \"adaptive_ridge_exact\", err_linear_adaptive_trained_one, yt_true)\n",
    "\n",
    "    println(\"\\n### βt Linear Decision Rule Adaptive with NO Stable Part and Trained ONCE STANDARD ###\")\n",
    "    ### Using Beta t+1 = Beta 0 + V0*Z_{t+1}, with Beta 0, V0 that is originating from the linear adaptive formulation with NO stable part\n",
    "    get_metrics(args, \"adaptive_ridge_standard\", err_linear_adaptive_trained_one_standard, yt_true)\n",
    "\n",
    "    #SAME AS LAST 2, BUT WITH ERROR RULES\n",
    "    println(\"\\n### βt Linear Decision Rule Adaptive with NO Stable Part and Trained ONCE + ERROR RULE for Z ###\")\n",
    "    ### Using Beta t+1 = Beta 0 + V0*Z_{t+1}, with Beta 0, V0 that is originating from the linear adaptive formulation with NO stable part\n",
    "    get_metrics(args, \"adaptive_ridge_exact_err_rule\", err_linear_adaptive_trained_one_err_rule, yt_true)\n",
    "\n",
    "    println(\"\\n### βt Linear Decision Rule Adaptive with NO Stable Part and Trained ONCE STANDARD + ERROR RULE for Z ###\")\n",
    "    ### Using Beta t+1 = Beta 0 + V0*Z_{t+1}, with Beta 0, V0 that is originating from the linear adaptive formulation with NO stable part\n",
    "    get_metrics(args, \"adaptive_ridge_standard_err_rule\", err_linear_adaptive_trained_one_standard_err_rule, yt_true)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "bc758d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set a size for training data\n",
    "N0 = 900\n",
    "\n",
    "#set a size for testing data\n",
    "Nt = 100\n",
    "\n",
    "#set a number of underlying models\n",
    "p = 10\n",
    "\n",
    "δ = 0.5\n",
    "δ_pert = 0.5\n",
    "σ_pert = 1\n",
    "#y = randn(N0+Nt)\n",
    "n0 = floor(Int, size(y_safi)[1]/2)\n",
    "y_true = y_safi[n0-N0:n0+Nt-1]\n",
    "y = copy(y_true)\n",
    "d = Uniform(-δ, δ)\n",
    "biases = rand(d, p)\n",
    "variances = rand(p)\n",
    "gradual_after = false\n",
    "gradual_before = true\n",
    "\n",
    "#Create the features X by taking y and adding noise.\n",
    "X = zeros(N0+Nt, p)\n",
    "\n",
    "for i=1:p\n",
    "    d = Normal(biases[i], variances[i])\n",
    "    X[:,i] = y.+ rand(d, N0+Nt)\n",
    "end\n",
    "\n",
    "#### Perturbations on base learners because of data drift\n",
    "d = Normal(0, δ_pert)\n",
    "biases_perturb = rand(d, p)\n",
    "d = Uniform(0, σ_pert)\n",
    "variances_perturb = rand(d, p)\n",
    "\n",
    "if gradual_after\n",
    "    for i=1:p\n",
    "        d = Normal(biases_perturb[i], variances_perturb[i])\n",
    "        #We add the perturbation for each model \n",
    "        #We make the perturbations more and more intense across time\n",
    "        X[N0+1:N0+Nt,i] = X[N0+1:N0+Nt,i].+rand(d, Nt).*[t/Nt for t=1:Nt]\n",
    "    end\n",
    "end\n",
    "\n",
    "if gradual_before\n",
    "    for i=1:p\n",
    "        for t=1:Nt\n",
    "            #We compute the perturbation for each model \n",
    "            #We make the perturbations more and more intense across time\n",
    "            d = Normal(t/Nt*δ_pert, t/Nt*σ_pert)\n",
    "            X[N0+t,i] = X[N0+t,i]+rand(d)\n",
    "        end\n",
    "    end\n",
    "else\n",
    "    for i=1:p\n",
    "        d = Normal(biases_perturb[i], variances_perturb[i])\n",
    "        #We add the perturbation for each model \n",
    "        #We make the perturbations more and more intense across time\n",
    "        X[N0+1:N0+Nt,i] = X[N0+1:N0+Nt,i].+rand(d, Nt)\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "2f90335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Perturbations on y\n",
    "perturb_y = true\n",
    "perturb_y_norm = true\n",
    "y_bias = -0.1\n",
    "y_var = 0.5\n",
    "\n",
    "if perturb_y\n",
    "    if perturb_y_norm\n",
    "        d = Normal(y_bias, y_var)\n",
    "        y[N0+1:N0+Nt] = y[N0+1:N0+Nt] .+ rand(d, Nt)\n",
    "    else\n",
    "        d = Uniform(-y_bias, y_bias)\n",
    "        y[N0+1:N0+Nt] = y[N0+1:N0+Nt] .+ rand(d, Nt)\n",
    "    end\n",
    "end\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a685535d",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: linear_adapt not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: linear_adapt not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[135]:25",
      " [2] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "split_ = N0/(N0+Nt)\n",
    "past = 10\n",
    "num_past = floor(Int, Nt/past)\n",
    "\n",
    "last_yT = false\n",
    "max_cuts = 10\n",
    "verbose = false\n",
    "\n",
    "uncertainty = 0.#1\n",
    "δ_inf = 0.02\n",
    "ϵ_inf = 0.02\n",
    "\n",
    "ϵ_l2 = 0.05\n",
    "δ_l2 = 0.05\n",
    "\n",
    "reg = 1/(past*num_past)\n",
    "ρ = 0.1\n",
    "val = Nt-1; #n-split_index;\n",
    "\n",
    "fix_β0 = false\n",
    "more_data_for_β0 = false\n",
    "benders = false\n",
    "ridge = true\n",
    "\n",
    "eval_method(X, y, y_true, split_, past, num_past, val, uncertainty, ϵ_inf, δ_inf, last_yT, \n",
    "        ϵ_l2, δ_l2, ρ, reg, max_cuts, verbose, \n",
    "        fix_β0, more_data_for_β0, benders, ridge, linear_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1d6a6fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "Result index of attribute MathOptInterface.ObjectiveValue(1) out of bounds. There are currently 0 solution(s) in the model.",
     "output_type": "error",
     "traceback": [
      "Result index of attribute MathOptInterface.ObjectiveValue(1) out of bounds. There are currently 0 solution(s) in the model.",
      "",
      "Stacktrace:",
      "  [1] check_result_index_bounds",
      "    @ /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/MathOptInterface/YDdD3/src/attributes.jl:139 [inlined]",
      "  [2] get(model::Gurobi.Optimizer, attr::MathOptInterface.ObjectiveValue)",
      "    @ Gurobi ~/.julia/packages/Gurobi/BAtIN/src/MOI_wrapper/MOI_wrapper.jl:3086",
      "  [3] get(b::MathOptInterface.Bridges.LazyBridgeOptimizer{Gurobi.Optimizer}, attr::MathOptInterface.ObjectiveValue)",
      "    @ MathOptInterface.Bridges /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/MathOptInterface/YDdD3/src/Bridges/bridge_optimizer.jl:913",
      "  [4] get(model::MathOptInterface.Utilities.CachingOptimizer{MathOptInterface.AbstractOptimizer, MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Utilities.GenericModel{Float64, MathOptInterface.Utilities.ModelFunctionConstraints{Float64}}}}, attr::MathOptInterface.ObjectiveValue)",
      "    @ MathOptInterface.Utilities /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [5] _moi_get_result(model::MathOptInterface.Utilities.CachingOptimizer{MathOptInterface.AbstractOptimizer, MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Utilities.GenericModel{Float64, MathOptInterface.Utilities.ModelFunctionConstraints{Float64}}}}, args::MathOptInterface.ObjectiveValue)",
      "    @ JuMP /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/qhoVb/src/JuMP.jl:848",
      "  [6] get(model::Model, attr::MathOptInterface.ObjectiveValue)",
      "    @ JuMP /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/qhoVb/src/JuMP.jl:861",
      "  [7] objective_value(model::Model; result::Int64)",
      "    @ JuMP /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/qhoVb/src/objective.jl:42",
      "  [8] objective_value",
      "    @ /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/qhoVb/src/objective.jl:42 [inlined]",
      "  [9] master_primal_l2_ridge(X0::Matrix{Float64}, Xt::Matrix{Float64}, y0::Vector{Float64}, Dmin::Vector{Float64}, Dmax::Vector{Float64}, epsilon::Float64, delta::Float64, reg::Float64, ρ::Float64, ϵ_l2::Float64, δ_l2::Float64, β0_fix::Bool, β0_val::Vector{Float64})",
      "    @ Main ./In[10]:114",
      " [10] eval_method(X::Matrix{Float64}, y::Vector{Float64}, y_true::Vector{Float64}, split_::Float64, past::Int64, num_past::Int64, val::Int64, uncertainty::Float64, ϵ_inf::Float64, δ_inf::Float64, last_yT::Bool, ϵ_l2::Float64, δ_l2::Float64, ρ::Float64, reg::Float64, max_cuts::Int64, verbose::Bool, fix_β0::Bool, more_data_for_β0::Bool, benders::Bool, ridge::Bool)",
      "    @ Main ./In[9]:74",
      " [11] top-level scope",
      "    @ In[136]:25",
      " [12] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [13] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "split_ = N0/(N0+Nt)\n",
    "past = 20\n",
    "num_past = floor(Int, Nt/past)\n",
    "\n",
    "last_yT = false\n",
    "max_cuts = 10\n",
    "verbose = false\n",
    "\n",
    "uncertainty = 0.#1\n",
    "δ_inf = 0.02\n",
    "ϵ_inf = 0.02\n",
    "\n",
    "ϵ_l2 = 0.05\n",
    "δ_l2 = 0.05\n",
    "\n",
    "reg = 1/(past*num_past)\n",
    "ρ = 0.1\n",
    "val = Nt-1; #n-split_index;\n",
    "\n",
    "fix_β0 = false\n",
    "more_data_for_β0 = false\n",
    "benders = false\n",
    "ridge = true\n",
    "\n",
    "eval_method(X, y, y_true, split_, past, num_past, val, uncertainty, ϵ_inf, δ_inf, last_yT, \n",
    "        ϵ_l2, δ_l2, ρ, reg, max_cuts, verbose, \n",
    "        fix_β0, more_data_for_β0, benders, ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de22ec33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "master_problem (generic function with 8 methods)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_Y(X, t)\n",
    "    \"\n",
    "    Create the vector of data for the dual problem\n",
    "    \"\n",
    "    T, p = size(X)\n",
    "    Y = zeros(1,T*p)\n",
    "    Y[(t-1)*p+1:t*p] = X[t,:]\n",
    "    return Y\n",
    "end\n",
    "\n",
    "function get_Z(X)\n",
    "    T, p = size(X)\n",
    "    Z = zeros(T, T*p)\n",
    "    for t=1:T\n",
    "        Z[t,:] = get_Y(X,t)\n",
    "    end\n",
    "    return Z\n",
    "end\n",
    "\n",
    "function get_A(X, t)\n",
    "    T, p = size(X)\n",
    "    A = zeros(p,T*p)\n",
    "    A[:,(t-1)*p+1:t*p] = 1 * Matrix(I, p, p)\n",
    "    return A\n",
    "end\n",
    "\n",
    "\n",
    "function solve_model_benders(m)\n",
    "    \"Solve the Benders master problem\n",
    "    \"\n",
    "    optimize!(m)\n",
    "    U_OA = objective_value(m)\n",
    "    #println(\"U_OA from solve \", U_OA)\n",
    "    return value.(m[:β]), value.(m[:α]), U_OA\n",
    "end\n",
    "\n",
    "function S_primal(X, y, β0, epsilon, delta)\n",
    "\n",
    "    n, p = size(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, β[i=1:n,j=1:p])\n",
    "    @variable(model, b[i=1:n]>=0)\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Min, sum(b[i] for i=1:n))\n",
    "\n",
    "    #@constraint(model,[i=1:n], y .- dot(X,β) .<= b)\n",
    "    #@constraint(model,[i=1:n],-y .+ dot(X,β) .<= b)\n",
    "\n",
    "\n",
    "    @constraint(model, res_plus[i=1:n],  - y[i] + dot(X[i,:],β[i,:]) <= b[i])\n",
    "    @constraint(model, res_minus[i=1:n],  y[i] - dot(X[i,:],β[i,:]) <= b[i])\n",
    "\n",
    "    @constraint(model, diff_plus[i=2:n],   β[i,:] .- β[i-1,:] .<= delta)\n",
    "    @constraint(model, diff_minus[i=2:n], - β[i,:] .+ β[i-1,:] .<= delta)\n",
    "\n",
    "    @constraint(model, diff_0_plus[i=1:n],   β[i,:] .- β0 .<= epsilon)\n",
    "    @constraint(model, diff_0_minus[i=1:n], - β[i,:] .+ β0 .<= epsilon)\n",
    "\n",
    "    optimize!(model);\n",
    "\n",
    "    return objective_value(model), getvalue.(β)\n",
    "end\n",
    "\n",
    "\n",
    "function R(X, D_min, D_max, β0, epsilon, delta)\n",
    "    \"\n",
    "    Full dual problem\n",
    "    \"\n",
    "    T, p = size(X)\n",
    "    Z = get_Z(X)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))#Model(with_optimizer(Gurobi.Optimizer))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    set_optimizer_attribute(model, \"NonConvex\", 2)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, λ[i=1:2, j=1:T] >= 0)\n",
    "    @variable(model, ν[i=1:2, j=1:T-1, k=1:p]>=0)\n",
    "    @variable(model, μ[i=1:2, j=1:T, k=1:p]>=0)\n",
    "\n",
    "    @variable(model, y[j=1:T])\n",
    "\n",
    "\n",
    "    @constraint(model,[t=1:T], λ[1,:] .+ λ[2,:] .== 1)\n",
    "\n",
    "\n",
    "    @constraint(model, transpose(λ[2,:])*Z-transpose(λ[1,:])*Z\n",
    "                        + sum(transpose(ν[1,t,:])*(get_A(X, t+1).-get_A(X, t)) for t=1:T-1)\n",
    "                        + sum(transpose(ν[2,t,:])*(-get_A(X, t+1).+get_A(X, t)) for t=1:T-1)\n",
    "                        + sum(transpose(μ[1,t,:])*get_A(X,t) for t=1:T)\n",
    "                        - sum(transpose(μ[2,t,:])*get_A(X,t) for t=1:T) .== 0)\n",
    "\n",
    "    #y in uncertainty set\n",
    "    @constraint(model, [1:T], D_min .<= y)\n",
    "    @constraint(model, [1:T], y .<= D_max)\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Max, 2*dot(λ[1,:],y) - sum(y)\n",
    "                            - delta * sum(sum(ν[1,t,i]+ν[2,t,i] for i=1:p) for t=1:T-1)\n",
    "                            - sum(dot(epsilon .+ β0, μ[1,t,:]) for t = 1:T)\n",
    "                            - sum(dot(epsilon .- β0, μ[2,t,:]) for t = 1:T)) #\n",
    "    optimize!(model)\n",
    "    return objective_value(model), getvalue.(y), getvalue.(λ), getvalue.(ν), getvalue.(μ)\n",
    "end\n",
    "\n",
    "function master_problem(X0, Xt, y0, D_min, D_max, threshold = 0.1, epsilon = 0.1, delta = 0.1, reg = 1, ρ = 1, max_cuts = 10, verbose=0)\n",
    "    n, p = size(X0)\n",
    "    T, p = size(Xt)\n",
    "    #Z = get_Z(X0)\n",
    "    L_BD = -10000\n",
    "    U_BD = 10000\n",
    "    cuts = 0\n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))#Model(with_optimizer(Gurobi.Optimizer))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, α)\n",
    "    @variable(model, β[j=1:p])\n",
    "\n",
    "    #Warm start for β\n",
    "\n",
    "    β_val0 = l2_regression(X0, y0, ρ)#Random.rand(p)#\n",
    "    #β_val0 = Random.rand(p)\n",
    "\n",
    "\n",
    "    #Initialization\n",
    "    _, y_val0, λ_val0, ν_val0, μ_val0 = R(Xt, D_min, D_max, β_val0, epsilon, delta)\n",
    "\n",
    "    #First constraint\n",
    "    @constraint(model, α >= 2*dot(λ_val0[1,:],y_val0) - sum(y_val0)\n",
    "                            - delta * sum(sum(ν_val0[1,t,i]+ν_val0[2,t,i] for i=1:p) for t=1:T-1)\n",
    "                            - sum(dot(epsilon .+ β, μ_val0[1,t,:]) for t = 1:T)\n",
    "                            - sum(dot(epsilon .- β, μ_val0[2,t,:]) for t = 1:T))\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Min, 1/n*sum((y0[i]-sum(X0[i,j]*β[j] for j=1:p))^2 for i=1:n) + reg*α + ρ*sum(β[j]^2 for j=1:p))\n",
    "\n",
    "    while cuts < max_cuts && U_BD - L_BD > threshold\n",
    "        if verbose\n",
    "            println(\"Lower: \", L_BD, \" Upper: \", U_BD)\n",
    "        end\n",
    "        cuts += 1\n",
    "\n",
    "        #Solve current Master Problem\n",
    "        β_val, α_val, L_BD = solve_model_benders(model)\n",
    "        U_OA, y_val, λ_val, ν_val, μ_val = R(Xt, D_min, D_max, β_val, epsilon, delta)\n",
    "\n",
    "        U_BD = 1/n*sum((y0[i]-sum(X0[i,j]*β_val[j] for j=1:p))^2 for i=1:n) + reg*U_OA + ρ*sum(β_val[j]^2 for j=1:p)\n",
    "\n",
    "        if U_BD - L_BD > threshold\n",
    "            @constraint(model, α >= 2*dot(λ_val[1,:],y_val) - sum(y_val)\n",
    "                            - delta * sum(sum(ν_val[1,t,i]+ν_val[2,t,i] for i=1:p) for t=1:T-1)\n",
    "                            - sum(dot(epsilon .+ β, μ_val[1,t,:]) for t = 1:T)\n",
    "                            - sum(dot(epsilon .- β, μ_val[2,t,:]) for t = 1:T))\n",
    "            if verbose\n",
    "                println(\"Cut added\")\n",
    "                println(\"y_val: \", y_val)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    optimize!(model)\n",
    "    β_val, α_val, L_BD = solve_model_benders(model)\n",
    "    U_OA, y_val, λ_val, ν_val, μ_val = R(Xt, D_min, D_max, β_val, epsilon, delta)\n",
    "    if verbose\n",
    "        println(\"Final model Obj value: \", objective_value(model))\n",
    "        println(\"Lower: \", L_BD, \" Upper: \", U_BD)\n",
    "        println(\"Final y: \", y_val)\n",
    "    end\n",
    "    return objective_value(model), getvalue.(β), getvalue.(α), y_val#, getvalue.(ν), getvalue.(μ)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6507fc79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "l2_regression (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function R2(y_true, y_test)\n",
    "    SSR = sum(abs2.(y_true.-y_test))\n",
    "    SST = sum(abs2.(y_true.-mean(y_true)))\n",
    "    return 1 - SSR/SST\n",
    "end\n",
    "\n",
    "function R2_err(err, y_true)\n",
    "    SSR = sum(abs2.(err))\n",
    "    SST = sum(abs2.(y_true.-mean(y_true)))\n",
    "    return 1 - SSR/SST\n",
    "end\n",
    "\n",
    "\n",
    "function compute_CVaR(errs, α_risk)\n",
    "#     '''\n",
    "#     Compute the Conditional Value at Risk\n",
    "#     :param X: Either the data matrix X or the errors\n",
    "#     :param y: the target values\n",
    "#     :param alpha: the risk value\n",
    "#     :param beta:\n",
    "#     :param b0:\n",
    "#     :param errs: whether you want to input the data matrix X or the errors\n",
    "#     :return: the model and the CVaR\n",
    "#     '''\n",
    "    n = size(errs)[1]\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, τ)\n",
    "    @variable(model, z[1:n] >= 0)\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Min, sum(z)/(α_risk * n) + τ)\n",
    "\n",
    "    @constraint(model, [1:n], errs .- τ .<= z)\n",
    "\n",
    "    optimize!(model)\n",
    "\n",
    "    return objective_value(model)\n",
    "end\n",
    "\n",
    "\n",
    "function eval_method(X, y, y_true, split_, past, num_past, val, uncertainty, ϵ_inf, δ_inf, last_yT,\n",
    "        ϵ_l2, δ_l2, ρ, reg, max_cuts, verbose,\n",
    "        fix_β0, more_data_for_β0, benders, ridge)\n",
    "\n",
    "    threshold_benders = 0.01\n",
    "    n, p = size(X)\n",
    "    split_index = floor(Int,n*split_)\n",
    "    #TODO change spli_index with max(split inex, 1)\n",
    "    X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, split_index-num_past*past+1, num_past*past, val, uncertainty, last_yT)\n",
    "\n",
    "    β_list0 = zeros(val, p)\n",
    "    β_listt = zeros(val, p)\n",
    "    β_listl2 = zeros(val, p)\n",
    "    β_l2_init = l2_regression(X0,y0,ρ);\n",
    "    for s=1:val\n",
    "\n",
    "        if more_data_for_β0\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, split_index-num_past*past+1, s+(num_past-1)*past, past-1, uncertainty, last_yT)\n",
    "        else\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, s+split_index-num_past*past+1, (num_past-1)*past, past-1, uncertainty, last_yT)\n",
    "        end\n",
    "\n",
    "\n",
    "        if benders\n",
    "            ##TODO handle fix_beta0\n",
    "            obj, β0_val, α, y_val = master_problem(X0, Xt, y0, D_min, D_max, threshold_benders, ϵ_inf, δ_inf, reg, ρ, max_cuts, verbose)\n",
    "            _, βt_val = S_primal(Xt, y_val, β0_val, ϵ_inf, δ_inf);\n",
    "        else\n",
    "            if ridge\n",
    "                obj, βt_val, β0_val = master_primal_l2_ridge(X0, Xt, y0, D_min, D_max, ϵ_inf, δ_inf, reg, ρ, ϵ_l2, δ_l2, fix_β0, β_l2_init)\n",
    "            else\n",
    "                obj, βt_val, β0_val = master_primal_l2(X0, Xt, y0, D_min, D_max, ϵ_inf, δ_inf, reg, ρ, ϵ_l2, δ_l2, fix_β0, β_l2_init)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        β_listt[s,:] = βt_val[past-1,:]\n",
    "        β_list0[s,:] = β0_val\n",
    "        β_l2 = l2_regression(X0,y0,ρ);\n",
    "        β_listl2[s,:] = β_l2\n",
    "\n",
    "    end\n",
    "\n",
    "    X0, y0, Xt, yt, _, D_min, D_max = prepare_data_from_y(X, y, 1, split_index, val, uncertainty, last_yT)\n",
    "    _, _, _, _, yt_true, _, _ = prepare_data_from_y(X, y_true, 1, split_index, val, uncertainty, last_yT)\n",
    "\n",
    "    err_0 = [abs(yt_true[s]-dot(Xt[s,:],β_list0[s,:])) for s=1:val]\n",
    "    err_t = [abs(yt_true[s]-dot(Xt[s,:],β_listt[s,:])) for s=1:val]\n",
    "    err_baseline = [abs(yt_true[s]-dot(Xt[s,:],β_l2_init)) for s=1:val]\n",
    "    err_l2 = [abs(yt_true[s]-dot(Xt[s,:],β_listl2[s,:])) for s=1:val]\n",
    "\n",
    "    println(\"\\n### β0 Baseline ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_baseline))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_baseline, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_baseline, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_baseline, yt_true))\n",
    "\n",
    "    println(\"\\n### β0 Baseline Retrained ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_l2))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_l2, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_l2, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_l2, yt_true))\n",
    "\n",
    "    println(\"\\n### β0 Adaptive ###\")\n",
    "    println(\"MAE 0: \", mean(err_0))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_0, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_0, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_0, yt_true))\n",
    "\n",
    "    println(\"\\n### βt Adaptive ###\")\n",
    "    println(\"MAE t: \", mean(err_t))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_t, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_t, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_t, yt_true))\n",
    "end\n",
    "\n",
    "\n",
    "function prepare_data_from_y(X, y, n0, n, m, uncertainty, last_yT = false)\n",
    "\n",
    "    X0 = Matrix(X[n0:n0+n,:])\n",
    "    X0[:,1] = ones(n+1)\n",
    "    y0 = y[n0:n0+n,:][:]\n",
    "\n",
    "    yt_true = y[n0+n+1:n0+n+m,:][:]\n",
    "    Xt = Matrix(X[n0+n+1:n0+n+m,:])\n",
    "    Xt[:,1] = ones(m)\n",
    "    yt = yt_true\n",
    "    if last_yT\n",
    "        yt_true[m] = mean(Xt[m])\n",
    "    end\n",
    "\n",
    "    D_min = yt .- uncertainty.*abs.(yt)\n",
    "    D_max = yt .+ uncertainty.*abs.(yt)\n",
    "\n",
    "    return X0, y0, Xt, yt, yt_true, D_min, D_max\n",
    "end\n",
    "\n",
    "\n",
    "function l2_regression(X, y, rho; solver_output=0)\n",
    "    n,p = size(X)\n",
    "\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", solver_output)\n",
    "    set_optimizer_attribute(model, \"NonConvex\", 2)\n",
    "\n",
    "    @variable(model,beta[j=1:p])\n",
    "    @variable(model, sse>=0)\n",
    "    #@variable(model, reg>=0)\n",
    "    @constraint(model, sum((y[i]-sum(X[i,j]*beta[j] for j=1:p))^2 for i=1:n) <= sse)\n",
    "    #@constraint(model, sum(beta[j]^2 for j=1:p)<=reg)\n",
    "    @objective(model,Min, 1/n*sse + rho*sum(beta[j]^2 for j=1:p))\n",
    "\n",
    "    optimize!(model)\n",
    "    #println(\"Obj \", objective_value(model))\n",
    "    return value.(beta)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0e484ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "master_primal_l2_ridge (generic function with 3 methods)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "function master_primal_l2(X0, Xt, y0, Dmin, Dmax, epsilon, delta, reg, ρ, ϵ_l2, δ_l2, β0_fix = false, β0_val = 0)\n",
    "\n",
    "    M = 1000\n",
    "    n0, p = size(X0)\n",
    "    n, _ = size(Xt)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, β[i=1:n,j=1:p])\n",
    "    @variable(model, b[i=1:n]>=0)\n",
    "    @variable(model, β0[j=1:p])\n",
    "    @variable(model, z[i=1:n], Bin)\n",
    "    @variable(model, y[i=1:n])\n",
    "    # Add objective\n",
    "    @objective(model, Min, 1/n0*sum((y0[i]-sum(X0[i,j]*β0[j] for j=1:p))^2 for i=1:n0)\n",
    "        + reg*sum(b[i] for i=1:n) + ρ*sum(β0[j]^2 for j=1:p))\n",
    "\n",
    "    #@constraint(model,[i=1:n], y .- dot(X,β) .<= b)\n",
    "    #@constraint(model,[i=1:n],-y .+ dot(X,β) .<= b)\n",
    "\n",
    "    if β0_fix\n",
    "        @constraint(model, β0 .== β0_val)\n",
    "    end\n",
    "    @constraint(model, res_plus_min[i=1:n],  - y[i] + dot(Xt[i,:],β[i,:]) <= b[i])\n",
    "    @constraint(model, res_minus_min[i=1:n],  y[i] - dot(Xt[i,:],β[i,:]) <= b[i])\n",
    "\n",
    "    @constraint(model,  y .== Dmax.*z + Dmin.*(1 .-z))\n",
    "    #@constraint(model,  y .== Dmax.*(1 .-z) + Dmin.*z)\n",
    "\n",
    "    #@constraint(model, bigM[i=1:n], (dot(Xt[i,:],β[i,:])-Dmin[i])^2 + M*z[i] >= (dot(Xt[i,:],β[i,:])-Dmax[i])^2)\n",
    "    @constraint(model, bigM[i=1:n], (dot(Xt[i,:],β[i,:]) - Dmin[i])^2 - (dot(Xt[i,:],β[i,:])-Dmax[i])^2 + M*z[i] >= 0)\n",
    "\n",
    "\n",
    "    #@constraint(model, bigM2[i=1:n],  (dot(Xt[i,:],β[i,:])-Dmax[i])^2 + M*(1-z[i]) >= (dot(Xt[i,:],β[i,:])-Dmin[i])^2)\n",
    "\n",
    "    @constraint(model, diff_plus[i=2:n],   β[i,:] .- β[i-1,:] .<= delta)\n",
    "    @constraint(model, diff_minus[i=2:n], - β[i,:] .+ β[i-1,:] .<= delta)\n",
    "\n",
    "    @constraint(model, diff_0_plus[i=1:n],   β[i,:] .- β0 .<= epsilon)\n",
    "    @constraint(model, diff_0_minus[i=1:n], - β[i,:] .+ β0 .<= epsilon)\n",
    "\n",
    "    @constraint(model, sq_0[i=1:n], sum((β[i,:] .- β0).^2) .<= ϵ_l2)\n",
    "    @constraint(model, sq_t[i=2:n], sum((β[i,:] .- β[i-1,:]).^2) .<= δ_l2)\n",
    "\n",
    "    #@constraint(model, abs_0[i=1:n], sum(abs.(β[i,:] .- β0)) .<= ϵ_l1)\n",
    "    #@constraint(model, abs_t[i=2:n], sum(abs.(β[i,:] .- β[i-1,:])) .<= δ_l1)\n",
    "\n",
    "    optimize!(model);\n",
    "    #println(\"SUM \", sum(getvalue.(b)))\n",
    "    #println(\"Y \", getvalue.(y))\n",
    "    return objective_value(model), getvalue.(β), getvalue.(β0)\n",
    "end\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "function master_primal_l2_ridge(X0, Xt, y0, Dmin, Dmax, epsilon, delta, reg, ρ, ϵ_l2, δ_l2, β0_fix = false, β0_val = 0)\n",
    "\n",
    "    M = 1000\n",
    "    n0, p = size(X0)\n",
    "    n, _ = size(Xt)\n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "\n",
    "    # Add variables\n",
    "    @variable(model, β[i=1:n,j=1:p])\n",
    "    @variable(model, β0[j=1:p])\n",
    "    @variable(model, z[i=1:n], Bin)\n",
    "    @variable(model, y[i=1:n])\n",
    "    # Add objective\n",
    "    @objective(model, Min, 1/n0*sum((y0[i]-sum(X0[i,j]*β0[j] for j=1:p))^2 for i=1:n0)\n",
    "        + reg*sum((y[i] - dot(Xt[i,:],β[i,:]))^2 for i=1:n) + ρ*sum(β0[j]^2 for j=1:p))\n",
    "\n",
    "    #@constraint(model,[i=1:n], y .- dot(X,β) .<= b)\n",
    "    #@constraint(model,[i=1:n],-y .+ dot(X,β) .<= b)\n",
    "\n",
    "    if β0_fix\n",
    "        @constraint(model, β0 .== β0_val)\n",
    "    end\n",
    "\n",
    "    @constraint(model,  y .== Dmax.*z + Dmin.*(1 .-z))\n",
    "    #@constraint(model,  y .== Dmax.*(1 .-z) + Dmin.*z)\n",
    "\n",
    "    #@constraint(model, bigM[i=1:n], (dot(Xt[i,:],β[i,:])-Dmin[i])^2 + M*z[i] >= (dot(Xt[i,:],β[i,:])-Dmax[i])^2)\n",
    "    @constraint(model, bigM[i=1:n], (dot(Xt[i,:],β[i,:]) - Dmin[i])^2 - (dot(Xt[i,:],β[i,:])-Dmax[i])^2 + M*z[i] >= 0)\n",
    "\n",
    "\n",
    "    #@constraint(model, bigM2[i=1:n],  (dot(Xt[i,:],β[i,:])-Dmax[i])^2 + M*(1-z[i]) >= (dot(Xt[i,:],β[i,:])-Dmin[i])^2)\n",
    "\n",
    "    @constraint(model, diff_plus[i=2:n],   β[i,:] .- β[i-1,:] .<= delta)\n",
    "    @constraint(model, diff_minus[i=2:n], - β[i,:] .+ β[i-1,:] .<= delta)\n",
    "\n",
    "    @constraint(model, diff_0_plus[i=1:n],   β[i,:] .- β0 .<= epsilon)\n",
    "    @constraint(model, diff_0_minus[i=1:n], - β[i,:] .+ β0 .<= epsilon)\n",
    "\n",
    "    @constraint(model, sq_0[i=1:n], sum((β[i,:] .- β0).^2) .<= ϵ_l2)\n",
    "    @constraint(model, sq_t[i=2:n], sum((β[i,:] .- β[i-1,:]).^2) .<= δ_l2)\n",
    "\n",
    "    #@constraint(model, abs_0[i=1:n], sum(abs.(β[i,:] .- β0)) .<= ϵ_l1)\n",
    "    #@constraint(model, abs_t[i=2:n], sum(abs.(β[i,:] .- β[i-1,:])) .<= δ_l1)\n",
    "\n",
    "    optimize!(model);\n",
    "    #println(\"SUM \", sum(getvalue.(b)))\n",
    "    #println(\"Y \", getvalue.(y))\n",
    "    return objective_value(model), getvalue.(β), getvalue.(β0)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87ecae3",
   "metadata": {},
   "source": [
    "# Linear rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69b65ed8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adaptive_ridge_regression_standard (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adaptive_ridge_regression_standard(X, y, ρ_β0, ρ_V0, T)\n",
    "    \n",
    "#     Adaptive ridge: does not run fast\n",
    "    \n",
    "\n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    X, Z, y = get_X_Z_y(X, y, T)\n",
    "\n",
    "    N, P = size(X)\n",
    "    # Add variables\n",
    "\n",
    "    @variable(model, β0[j=1:P])\n",
    "    @variable(model, V0[j=1:P, k=1:T*P+T])\n",
    "    @variable(model, t>=0)\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Min, t + ρ_β0 * sum(β0[j]^2 for j=1:P)\n",
    "                            + ρ_V0 * sum(V0[j,k]^2 for j=1:P for k=1:T*P+T)\n",
    "    )\n",
    "\n",
    "    @constraint(model, t >= 1 / N * sum((y[i] - sum(X[i, j] * (β0[j]\n",
    "                 + sum(V0[j, l] * Z[i, l] for l=1:(T * P + T))\n",
    "                 )\n",
    "                for j=1:P))^2\n",
    "        for i=1:N))\n",
    "\n",
    "    optimize!(model);\n",
    "    return objective_value(model), getvalue.(β0), getvalue.(V0), Z\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "71f6b698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adaptive_ridge_regression_before_exact (generic function with 1 method)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adaptive_ridge_regression_before_exact(X, y, ρ_β0, ρ_V0, T)\n",
    "    \n",
    "    #Version with actual robust equivalence\n",
    "    #We use beta t\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 1)\n",
    "    X, Z, y = get_X_Z_y(X, y, T)\n",
    "\n",
    "    N, P = size(X)\n",
    "    # Add variables\n",
    "\n",
    "    @variable(model, β0[j=1:P])\n",
    "    @variable(model, V0[j=1:P, k=1:T*P+T])\n",
    "    @variable(model, t>=0)\n",
    "    @variable(model, β[t=1:N,j=1:P])\n",
    "\n",
    "    # Add objective\n",
    "    @objective(model, Min, t + ρ_β0 * sum(β0[j]^2 for j=1:P)\n",
    "                            + ρ_V0 * sum(V0[j,k]^2 for j=1:P for k=1:T*P+T)\n",
    "    )\n",
    "\n",
    "    @constraint(model, t >= 1 / N * sum((y[i] - sum(transpose(X[i, :])*β[i,:]))^2 for i=1:N))\n",
    "        \n",
    "    @constraint(model, [i=1:N], β[i,:] .== β0+V0*Z[i,:])\n",
    "\n",
    "    optimize!(model);\n",
    "    return objective_value(model), getvalue.(β0), getvalue.(V0), getvalue.(β)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "772fd01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adaptive_ridge_regression_exact (generic function with 2 methods)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function adaptive_ridge_regression_exact(X, y, ρ_β0, ρ_V0, T, N0)\n",
    "    \n",
    "    #Version with actual robust equivalence\n",
    "    #The formula for the regularization is different\n",
    "    \n",
    "    # Create model\n",
    "    model = Model(with_optimizer(Gurobi.Optimizer, GRB_ENV))\n",
    "    set_optimizer_attribute(model, \"OutputFlag\", 0)\n",
    "    X, Z, y = get_X_Z_y(X, y, T)\n",
    "\n",
    "    N, P = size(X)\n",
    "    # Add variables\n",
    "\n",
    "    @variable(model, β0[j=1:P])\n",
    "    @variable(model, V0[j=1:P, k=1:T*P+T])\n",
    "    @variable(model, t>=0)\n",
    "    @variable(model, β[t=1:N,j=1:P])\n",
    "\n",
    "    # If no stable part, then no reg\n",
    "    if N0 == 1\n",
    "        ρ_β0 = 0\n",
    "    end\n",
    "    \n",
    "    # Add objective\n",
    "    @objective(model, Min, t + 1/N0*ρ_β0 * sum(β0[j]^2 for j=1:P)\n",
    "                            + 1/(N-N0)*ρ_V0 * sum(β[t,k]^2 for t=1:N for k=1:P)\n",
    "    )\n",
    "\n",
    "    @constraint(model, t >= 1 / N * sum((y[i] - sum(transpose(X[i, :])*β[i,:]))^2 for i=1:N))\n",
    "    \n",
    "    #stable and adaptive part\n",
    "    @constraint(model, [i=N0:N], β[i,:] .== β0+V0*Z[i,:])\n",
    "    @constraint(model, [i=1:N0-1], β[i,:] .== β0)\n",
    "\n",
    "    optimize!(model);\n",
    "    return objective_value(model), getvalue.(β0), getvalue.(V0), getvalue.(β)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb71aa00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_X_Z_y (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_X_Z_y(X, y, T)\n",
    "    \"\"\"\n",
    "    Input: training data X and corresponding labels y ; T: how many time-steps from the past to be used\n",
    "    Output: the past features X with past targets y as a Z training data (no present features)\n",
    "    \"\"\"\n",
    "    n, p = size(X)\n",
    "    #T past time steps * p features + T targets\n",
    "    Z = ones(n-T, T*p+T)\n",
    "    for i=T+1:n\n",
    "        for t=1:T\n",
    "            Z[i-T,1+p*(t-1):p*t] = X[i-t,:]\n",
    "        end\n",
    "        Z[i-T, (p*T+1):end] = y[i-T:i-1]\n",
    "    end\n",
    "    return X[T+1:end,:], Z, y[T+1:end]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6c2e09a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.953041262548516 0.4782870249686575; 1.0535457742742587 0.334867774903859], [0.6507019593290054 0.4323663266396612 … -0.24864108988725883 0.4349146279684725; 0.953041262548516 0.4782870249686575 … 0.4349146279684725 0.7909332310183326], [0.7909332310183326, 0.7909332310183326])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e, Z, f = get_X_Z_y(X[1:5,1:2], y[1:5], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "3b08d166",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.019454798289416986\n"
     ]
    }
   ],
   "source": [
    "obj, β0, V0, Z = adaptive_ridge_regression_standard(X[1:100,1:3], y[1:100], 0.1, 0.1, 3)\n",
    "println(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "14aca550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.1504249753800681\n",
       " 0.4548341433068424\n",
       " 0.14489314118672222"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "β0+V0*Z[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "01ea2fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5860827402650841\n"
     ]
    }
   ],
   "source": [
    "obj, β0, V0, β = adaptive_ridge_regression_exact(X[1:100,1:3], y[1:100], 0, 0.1, 3, 16)\n",
    "println(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "2f73bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5852809828471135\n"
     ]
    }
   ],
   "source": [
    "obj, β0, V0, β = adaptive_ridge_regression_exact(X[1:100,1:3], y[1:100], 0, 0.1, 3, 0)\n",
    "println(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "55ad112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 291 rows, 331 columns and 4074 nonzeros\n",
      "Model fingerprint: 0x6c09b65a\n",
      "Model has 39 quadratic objective terms\n",
      "Model has 1 quadratic constraint\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 3e+00]\n",
      "  QMatrix range    [1e-06, 8e-02]\n",
      "  QLMatrix range   [6e-05, 1e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [2e-01, 2e-01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "  QRHS range       [8e-01, 8e-01]\n",
      "Presolve time: 0.00s\n",
      "Presolved: 391 rows, 432 columns, 4759 nonzeros\n",
      "Presolved model has 2 second-order cone constraints\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " Dense cols : 41\n",
      " Free vars  : 291\n",
      " AA' NZ     : 4.854e+03\n",
      " Factor NZ  : 1.827e+04\n",
      " Factor Ops : 8.039e+05 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.11421765e+00  5.36029178e-01  1.07e+00 2.06e-01  1.66e-02     0s\n",
      "   1   1.24866824e+00 -1.49454176e-01  1.71e-06 3.65e-07  9.92e-03     0s\n",
      "   2   8.61394373e-02  2.04473484e-03  5.59e-08 8.84e-08  5.96e-04     0s\n",
      "   3   3.58614220e-02  4.45432877e-03  1.72e-08 9.75e-14  2.23e-04     0s\n",
      "   4   2.59765144e-02  1.04984114e-02  4.71e-09 5.29e-14  1.10e-04     0s\n",
      "   5   2.04917687e-02  1.25069818e-02  1.27e-09 3.85e-15  5.66e-05     0s\n",
      "   6   2.02737134e-02  1.76733783e-02  8.11e-10 5.52e-15  1.84e-05     0s\n",
      "   7   1.97504484e-02  1.93025152e-02  2.43e-14 7.55e-15  3.18e-06     0s\n",
      "   8   1.94566600e-02  1.94498483e-02  2.57e-09 2.24e-09  4.84e-08     0s\n",
      "   9   1.94547804e-02  1.94546020e-02  2.00e-09 5.52e-11  1.27e-09     0s\n",
      "\n",
      "Barrier solved model in 9 iterations and 0.11 seconds\n",
      "Optimal objective 1.94547804e-02\n",
      "\n",
      "\n",
      "User-callback calls 62, time in user-callback 0.00 sec\n",
      "0.019454780357772428\n",
      "[0.1504354548405991, 0.45487816131635345, 0.14490341051823682]\n",
      "[0.15043545467982017, 0.4548781608300493, 0.14490341036312396]\n"
     ]
    }
   ],
   "source": [
    "obj, β0, V0, β = adaptive_ridge_regression_before_exact(X[1:100,1:3], y[1:100], 0.1, 0.1, 3)\n",
    "println(obj)\n",
    "println(β0+V0*Z[1,:])\n",
    "println(β[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "002f9b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gurobi Optimizer version 9.1.2 build v9.1.2rc0 (mac64)\n",
      "Thread count: 8 physical cores, 8 logical processors, using up to 8 threads\n",
      "Optimize a model with 291 rows, 331 columns and 4074 nonzeros\n",
      "Model fingerprint: 0xac638d92\n",
      "Model has 39 quadratic objective terms\n",
      "Model has 1 quadratic constraint\n",
      "Coefficient statistics:\n",
      "  Matrix range     [1e-02, 3e+00]\n",
      "  QMatrix range    [2e-01, 1e+01]\n",
      "  QLMatrix range   [6e-01, 4e+00]\n",
      "  Objective range  [1e+00, 1e+00]\n",
      "  QObjective range [2e-01, 2e-01]\n",
      "  Bounds range     [0e+00, 0e+00]\n",
      "  RHS range        [0e+00, 0e+00]\n",
      "  QRHS range       [8e-01, 8e-01]\n",
      "Presolve removed 291 rows and 291 columns\n",
      "Presolve time: 0.00s\n",
      "Presolved: 42 rows, 83 columns, 864 nonzeros\n",
      "Presolved model has 2 second-order cone constraints\n",
      "Ordering time: 0.00s\n",
      "\n",
      "Barrier statistics:\n",
      " AA' NZ     : 8.600e+02\n",
      " Factor NZ  : 9.030e+02\n",
      " Factor Ops : 2.558e+04 (less than 1 second per iteration)\n",
      " Threads    : 1\n",
      "\n",
      "                  Objective                Residual\n",
      "Iter       Primal          Dual         Primal    Dual     Compl     Time\n",
      "   0   3.61515699e+00  7.44923934e-01  3.25e-01 3.18e+00  7.19e-02     0s\n",
      "   1   6.42215881e-01  3.85814230e-01  3.57e-07 5.34e-01  1.06e-02     0s\n",
      "   2   5.73290854e-02 -4.33568773e-02  1.09e-08 7.66e-03  1.33e-03     0s\n",
      "   3   2.49646918e-02  1.65629209e-02  3.98e-13 4.86e-04  1.09e-04     0s\n",
      "   4   2.00952502e-02  1.91575779e-02  1.61e-13 5.35e-10  1.13e-05     0s\n",
      "   5   1.94626577e-02  1.94368039e-02  2.76e-12 1.48e-11  3.11e-07     0s\n",
      "   6   1.94554365e-02  1.94518164e-02  3.70e-12 1.78e-12  4.36e-08     0s\n",
      "   7   1.94547983e-02  1.94547552e-02  7.29e-10 9.21e-13  5.15e-10     0s\n",
      "\n",
      "Barrier solved model in 7 iterations and 0.02 seconds\n",
      "Optimal objective 1.94547983e-02\n",
      "\n",
      "\n",
      "User-callback calls 56, time in user-callback 0.00 sec\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Vector{Float64}:\n",
       " 0.1504249753800681\n",
       " 0.45483414330684235\n",
       " 0.14489314118672222"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, β0, V0, β, X1, Z1 = adaptive_ridge_regression_exact_test(X[1:100,1:3], y[1:100], 0.1, 0.1, 3)\n",
    "β[1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "2e470d86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533767797757831"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, P = size(X1)\n",
    "i = 1\n",
    "T = 3\n",
    "sum(X1[i, j] * (β0[j]+ sum(V0[j, l] * Z1[i, l] for l=1:(T * P + T))) for j=1:P)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87684819",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.533767797757831"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transpose(X1[i,:])*β[i,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "25386963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1504249753800681\n",
      "[0.1504249753800681, 0.4548341433068424, 0.14489314118672222]\n"
     ]
    }
   ],
   "source": [
    "j = 1\n",
    "println(β0[j]+sum(V0[j, l] * Z[i, l] for l=1:(T * P + T)))\n",
    "println(β0+V0*Z[i,:])\n",
    "println()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a313920b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_adaptive (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate_adaptive(X, y, y_true, β0, V0, T)\n",
    "    X, Z, y = get_X_Z_y(X, y, T)\n",
    "    \n",
    "    N, P = size(X)\n",
    "\n",
    "    pred = [sum(X[i, j] * (β0[j] + sum(V0[j, :] .* Z[i, :])) for j=1:P) for i=1:N]\n",
    "    if size(y_true) == size(pred)\n",
    "        err = [abs(y_true[i]-pred[i]) for i=1:N]\n",
    "    else\n",
    "        y_true = y_true[T+1:end]\n",
    "        err = [abs(y_true[i]-pred[i]) for i=1:N]\n",
    "    end\n",
    "    return err\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "bbb311d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evaluate_adaptive_retrained (generic function with 1 method)"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function evaluate_adaptive_retrained(X, y, y_true, β0_list, V0_list, T)\n",
    "    X, Z, y = get_X_Z_y(X, y, T)\n",
    "    \n",
    "    N, P = size(X)\n",
    "\n",
    "    pred = [sum(X[i, j] * (β0_list[i,j] + sum(V0_list[i, j, :] .* Z[i, :])) for j=1:P) for i=1:N]\n",
    "    if size(y_true) == size(pred)\n",
    "        err = [abs(y_true[i]-pred[i]) for i=1:N]\n",
    "    else\n",
    "        y_true = y_true[T+1:end]\n",
    "        err = [abs(y_true[i]-pred[i]) for i=1:N]\n",
    "    end\n",
    "    return err\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "id": "1a0ebb83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.2772791481270517, -0.22139104249186187, 0.25353125721465, 0.13052228762534424, 0.16184232903639695, 0.02133275894336177, -0.23829147212091226, 0.14926772611852196, 0.28826028113700647, 0.7460128800839689  …  0.6974694989745849, 0.4334507651952026, 0.4535167025297599, 0.4228111533412082, -0.9470370564072363, -0.004111494312688896, 0.12274140243903106, 0.08108513878897414, -1.4025705199739362, 0.08251350395763898], [0.7111257347162706, 0.768332857553357, 0.1994216466416816, 0.6812973681052467, 0.08794262534614797, 0.24054297764516547, 0.02174221306394139, 0.4729100683816176, 0.04127284032870793, 0.5794229469798875  …  0.29188476681020137, 0.3992553152476475, 0.02696830662909544, 0.5024620796474668, 0.7050416471102421, 0.23408638321844036, 0.4254973199898675, 0.7075806393798176, 0.9146849288371715, 0.6178682421677187])"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred, err = evaluate_adaptive(X[1:100,1:3], y[1:100], y[4:100], β0, V0, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "8059e02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "eval_method (generic function with 2 methods)"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function eval_method(X, y, y_true, split_, past, num_past, val, uncertainty, ϵ_inf, δ_inf, last_yT,\n",
    "        ϵ_l2, δ_l2, ρ, reg, max_cuts, verbose,\n",
    "        fix_β0, more_data_for_β0, benders, ridge, linear_adapt)\n",
    "\n",
    "    threshold_benders = 0.01\n",
    "    n, p = size(X)\n",
    "    split_index = floor(Int,n*split_)\n",
    "    #TODO change spli_index with max(split inex, 1)\n",
    "    X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, split_index-num_past*past+1, num_past*past, val, uncertainty, last_yT)\n",
    "\n",
    "    β_list0 = zeros(val, p)\n",
    "    β_listt = zeros(val, p)\n",
    "    β_listl2 = zeros(val, p)\n",
    "    β_l2_init = l2_regression(X0,y0,ρ);\n",
    "    β0_list_linear_adapt = zeros(val, p)\n",
    "    V0_list_linear_adapt = zeros(val, p, (past-1)*p+past-1)\n",
    "    err = ones(val)\n",
    "    \n",
    "    ###Linear decision rule\n",
    "    _, β0_0, V0_0 = adaptive_ridge_regression_standard(X0, y0, ρ, ρ, past-1)\n",
    "    print(size(V0))\n",
    "    \n",
    "    for s=1:val\n",
    "        #TODO Check how much I use from the past\n",
    "        if more_data_for_β0\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, split_index-num_past*past+1, s+(num_past-1)*past, past-1, uncertainty, last_yT)\n",
    "        else\n",
    "            X0, y0, Xt, yt, yt_true, D_min, D_max = prepare_data_from_y(X, y, s+split_index-num_past*past+1, (num_past-1)*past, past-1, uncertainty, last_yT)\n",
    "        end\n",
    "\n",
    "        if benders\n",
    "            ##TODO handle fix_beta0\n",
    "            obj, β0_val, α, y_val = master_problem(X0, Xt, y0, D_min, D_max, threshold_benders, ϵ_inf, δ_inf, reg, ρ, max_cuts, verbose)\n",
    "            _, βt_val = S_primal(Xt, y_val, β0_val, ϵ_inf, δ_inf);\n",
    "        else\n",
    "            if ridge\n",
    "                obj, βt_val, β0_val = master_primal_l2_ridge(X0, Xt, y0, D_min, D_max, ϵ_inf, δ_inf, reg, ρ, ϵ_l2, δ_l2, fix_β0, β_l2_init)\n",
    "            else\n",
    "                obj, βt_val, β0_val = master_primal_l2(X0, Xt, y0, D_min, D_max, ϵ_inf, δ_inf, reg, ρ, ϵ_l2, δ_l2, fix_β0, β_l2_init)\n",
    "            end\n",
    "        end\n",
    "        \n",
    "        if linear_adapt\n",
    "            #err[s] = evaluate_adaptive(vcat(X0[end-past+2:end,:],Xt), vcat(y0[end-past+2:end,:],yt), yt_true, β0, V0, past)\n",
    "            _, β0, V0 = adaptive_ridge_regression_standard(vcat(X0,Xt), vcat(y0,yt), ρ, ρ, past-1)\n",
    "            β0_list_linear_adapt[s,:] = β0\n",
    "            V0_list_linear_adapt[s,:,:] = V0\n",
    "            N = size(X0)[1]\n",
    "        end\n",
    "        \n",
    "        β_listt[s,:] = βt_val[past-1,:]\n",
    "        β_list0[s,:] = β0_val\n",
    "        β_l2 = l2_regression(vcat(X0,Xt),vcat(y0,yt),ρ);\n",
    "        β_listl2[s,:] = β_l2\n",
    "\n",
    "    end\n",
    "\n",
    "    X0, y0, Xt, yt, _, D_min, D_max = prepare_data_from_y(X, y, 1, split_index, val, uncertainty, last_yT)\n",
    "    _, _, _, _, yt_true, _, _ = prepare_data_from_y(X, y_true, 1, split_index, val, uncertainty, last_yT)\n",
    "\n",
    "    N = size(X0)[1]\n",
    "    err_linear_rule = evaluate_adaptive(vcat(X0[N-past+2:end,:],Xt), vcat(y0[N-past+2:end,:],yt), yt_true, β0_0, V0_0, past-1)\n",
    "    err_linear_rule_retrained = evaluate_adaptive_retrained(vcat(X0[N-past+2:end,:],Xt), vcat(y0[N-past+2:end,:],yt), \n",
    "        yt_true, β0_list_linear_adapt, V0_list_linear_adapt, past-1)\n",
    "    \n",
    "    err_0 = [abs(yt_true[s]-dot(Xt[s,:],β_list0[s,:])) for s=1:val]\n",
    "    err_t = [abs(yt_true[s]-dot(Xt[s,:],β_listt[s,:])) for s=1:val]\n",
    "    err_baseline = [abs(yt_true[s]-dot(Xt[s,:],β_l2_init)) for s=1:val]\n",
    "    err_l2 = [abs(yt_true[s]-dot(Xt[s,:],β_listl2[s,:])) for s=1:val]\n",
    "\n",
    "    println(\"\\n### β0 Baseline ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_baseline))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_baseline, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_baseline, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_baseline, yt_true))\n",
    "\n",
    "    println(\"\\n### β0 Baseline Retrained ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_l2))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_l2, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_l2, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_l2, yt_true))\n",
    "    \n",
    "    println(\"\\n### β0 V0 Linear rule Adaptive ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_linear_rule))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_linear_rule, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_linear_rule, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_linear_rule, yt_true))\n",
    "    \n",
    "    println(\"\\n### β0 V0 Linear rule Adaptive Retrained ###\")\n",
    "    println(\"MAE Baseline: \", mean(err_linear_rule_retrained))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_linear_rule_retrained, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_linear_rule_retrained, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_linear_rule_retrained, yt_true))\n",
    "\n",
    "    println(\"\\n### β0 Adaptive ###\")\n",
    "    println(\"MAE 0: \", mean(err_0))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_0, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_0, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_0, yt_true))\n",
    "\n",
    "    println(\"\\n### βt Adaptive ###\")\n",
    "    println(\"MAE t: \", mean(err_t))\n",
    "    println(\"CVAR 0.05 :\", compute_CVaR(err_t, 0.05))\n",
    "    println(\"CVAR 0.15 :\", compute_CVaR(err_t, 0.15))\n",
    "    println(\"R2 : \", R2_err(err_t, yt_true))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "f1f231c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 12)"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "Gurobi Error 10020: Constraint Q not PSD (diagonal adjustment of 1.1e-05 would be required). Set NonConvex parameter to 2 to solve model.",
     "output_type": "error",
     "traceback": [
      "Gurobi Error 10020: Constraint Q not PSD (diagonal adjustment of 1.1e-05 would be required). Set NonConvex parameter to 2 to solve model.",
      "",
      "Stacktrace:",
      "  [1] _check_ret",
      "    @ ~/.julia/packages/Gurobi/BAtIN/src/MOI_wrapper/MOI_wrapper.jl:326 [inlined]",
      "  [2] _check_ret_GRBoptimize(model::Gurobi.Optimizer)",
      "    @ Gurobi ~/.julia/packages/Gurobi/BAtIN/src/MOI_wrapper/MOI_wrapper.jl:343",
      "  [3] optimize!(model::Gurobi.Optimizer)",
      "    @ Gurobi ~/.julia/packages/Gurobi/BAtIN/src/MOI_wrapper/MOI_wrapper.jl:2672",
      "  [4] optimize!(b::MathOptInterface.Bridges.LazyBridgeOptimizer{Gurobi.Optimizer})",
      "    @ MathOptInterface.Bridges /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/MathOptInterface/YDdD3/src/Bridges/bridge_optimizer.jl:319",
      "  [5] optimize!(m::MathOptInterface.Utilities.CachingOptimizer{MathOptInterface.AbstractOptimizer, MathOptInterface.Utilities.UniversalFallback{MathOptInterface.Utilities.GenericModel{Float64, MathOptInterface.Utilities.ModelFunctionConstraints{Float64}}}})",
      "    @ MathOptInterface.Utilities /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [6] optimize!(model::Model, optimizer_factory::Nothing; bridge_constraints::Bool, ignore_optimize_hook::Bool, kwargs::Base.Iterators.Pairs{Union{}, Union{}, Tuple{}, NamedTuple{(), Tuple{}}})",
      "    @ JuMP /Applications/Julia-1.6.app/Contents/Resources/julia/lib/julia/sys.dylib:-1",
      "  [7] optimize! (repeats 2 times)",
      "    @ /Users/iai/builds/InterpretableAI/SystemImage/SysImgBuilder/.julia/packages/JuMP/qhoVb/src/optimizer_interface.jl:106 [inlined]",
      "  [8] adaptive_ridge_regression_standard(X::Matrix{Float64}, y::Vector{Float64}, ρ_β0::Float64, ρ_V0::Float64, T::Int64)",
      "    @ Main ./In[24]:29",
      "  [9] eval_method(X::DataFrame, y::Vector{Float64}, y_true::Vector{Float64}, split_::Float64, past::Int64, num_past::Int64, val::Int64, uncertainty::Float64, ϵ_inf::Float64, δ_inf::Float64, last_yT::Bool, ϵ_l2::Float64, δ_l2::Float64, ρ::Float64, reg::Float64, max_cuts::Int64, verbose::Bool, fix_β0::Bool, more_data_for_β0::Bool, benders::Bool, ridge::Bool, linear_adapt::Bool)",
      "    @ Main ./In[196]:45",
      " [10] top-level scope",
      "    @ In[198]:26",
      " [11] eval",
      "    @ ./boot.jl:360 [inlined]",
      " [12] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "linear_adapt = true\n",
    "split_ = N0/(N0+Nt)\n",
    "past = 5\n",
    "num_past = 20#floor(Int, Nt/past)\n",
    "\n",
    "last_yT = false\n",
    "max_cuts = 10\n",
    "verbose = false\n",
    "\n",
    "uncertainty = 0.#1\n",
    "δ_inf = 0.02\n",
    "ϵ_inf = 0.02\n",
    "\n",
    "ϵ_l2 = 0.05\n",
    "δ_l2 = 0.05\n",
    "\n",
    "reg = 1/(past*num_past)\n",
    "ρ = 0.1\n",
    "val = Nt-1; #n-split_index;\n",
    "\n",
    "fix_β0 = false\n",
    "more_data_for_β0 = false\n",
    "benders = false\n",
    "ridge = true\n",
    "\n",
    "eval_method(X, y, y_true, split_, past, num_past, val, uncertainty, ϵ_inf, δ_inf, last_yT, \n",
    "        ϵ_l2, δ_l2, ρ, reg, max_cuts, verbose, \n",
    "        fix_β0, more_data_for_β0, benders, ridge, linear_adapt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a8f815",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.2",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
